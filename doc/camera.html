<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>satcamsim.camera API documentation</title>
<meta name="description" content="Provides Camera and Sensor classes with different methods for image simulation, as well as auxiliary classes Cam_pose and Interior_orientation." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>satcamsim.camera</code></h1>
</header>
<section id="section-intro">
<p>Provides Camera and Sensor classes with different methods for image simulation, as well as auxiliary classes Cam_pose and Interior_orientation.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Provides Camera and Sensor classes with different methods for image simulation, as well as auxiliary classes Cam_pose and Interior_orientation.&#34;&#34;&#34;

import numpy as np
from itertools import chain
from scipy.signal import convolve2d
import pyproj
import rasterio
from shapely.geometry import Polygon
from shapely.ops import unary_union
from concurrent.futures import ThreadPoolExecutor
import multiprocessing as mp

from .input_imgs import DOP_processor, Feature_finder
from .save_output import Temp_handler
from .support import get_config, rotation_x, rotation_y, rotation_z
from .sim_modes import Sim_modes


class Camera:
    &#34;&#34;&#34;
    Camera object with pose and sensors attributes.

    Returns
    -------
    None.

    &#34;&#34;&#34;

    def __init__(self):
        self.sensors = []
        self.pose = None
        return

    def add_sensor(self, sensor):
        &#34;&#34;&#34;
        Append additional Sensor object to Camera&#39;s list of sensors.

        Parameters
        ----------
        sensor : Sensor
            sensor to be appended.

        Returns
        -------
        self : Camera
            updated camera instance.

        &#34;&#34;&#34;
        self.sensors.append(sensor)
        return self

    def set_pose(self, pose):
        &#34;&#34;&#34;
        Specify exterior orientation of camera.

        Parameters
        ----------
        pose : Cam_pose
            pose of the camera

        Returns
        -------
        self : Camera
            updated camera instance.
        &#34;&#34;&#34;
        self.pose = pose
        for sensor in self.sensors:
            sensor.pose = self.pose
        return self

    def take_line_img(self, dop_processor, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
        &#34;&#34;&#34;
        Acquire a single line image from the current pose using the specified sensors.

        Parameters
        ----------
        dop_processor : DOP_processor
            DOP_processor instance used to read data from DOP.
        active_sensors : list of Sensor, optional
            Sensor objects to be used for the image. If not given, all sensors
            are used.
        out_array : np.ndarray, optional
            output array for in-place writing. If not given, a new array is created.
        config : Config, optional
            Dict of config parameters. If not given, default parameters are used.
        feat_finder : Feature_finder, optional
            Feature_finder instance used to detect GCPs.

        Returns
        -------
        img_out : np.ndarray of np.uint8
            array of simulated images, shape (n_sensors, n_bands, 1, n_pixels).
        coverage : Polygon or MultiPolygon
            Polygon or collection of Polygons representing the ground track coverage.
        found_feats : list
            list of found GCPs.

        &#34;&#34;&#34;
        if active_sensors is None:
            active_sensors = self.sensors

        if out_array is None:
            num_bands = max([len(sensor.bands) for sensor in active_sensors])
            num_pixels = max([sensor.pixels for sensor in active_sensors])
            img_out = np.full((len(active_sensors), num_bands, num_pixels), np.NaN, np.uint8)
        else:
            img_out = out_array

        coverage_geoms = list()
        found_feats = list()

        for sensor_idx, sensor in enumerate(active_sensors):
            # take line images with all specified sensors
            img_out[sensor_idx, :, :], new_coverage, new_feats = sensor.take_line_img(dop_processor, config, feat_finder)

            # add ground covered in new line image
            coverage_geoms.append(new_coverage)
            found_feats += new_feats

        coverage = unary_union(coverage_geoms)  # union of ground track coverage of individual pixels
        return img_out, coverage, found_feats

    def default_swath(self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
        &#34;&#34;&#34;
        Take image composed of line scans from specified poses.

        Parameters
        ----------
        pose_list : list of Cam_pose
            List of poses to be used for the individual line images.
        active_sensors : list of Sensor, optional
            sensor objects to be used for the image. If not given, all sensors
            are used.
        out_array : np.ndarray, optional
            output array for in-place writing. If not given, a new array is created.
        config : Config, optional
            Dict of config parameters. If not given, default parameters are used.
        feat_finder : Feature_finder, optional
            Feature_finder instance used to detect GCPs.

        Returns
        -------
        img_out : np.array
            array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).
        coverage : shapely.geoms.Polygon or MultiPolygon
            Polygon or collection of Polygons representing the ground track coverage.
        found_feats : list
            list of found GCPs.

        &#34;&#34;&#34;
        with rasterio.Env() as rio_env:
            if active_sensors is None:
                active_sensors = self.sensors

            num_lines = len(pose_list)                                           # height of output image

            if out_array is None:
                num_bands = max([len(sensor.bands) for sensor in active_sensors])    # number of channels of output image
                num_pixels = max([sensor.pixels for sensor in active_sensors])       # width if output image

                # create array containing output images for all sensors and bands
                img_out = np.full((len(active_sensors), num_bands, num_lines, num_pixels), np.NaN, np.uint8)
            else:
                img_out = out_array

            coverage_geoms = list()
            found_feats = list()

            with DOP_processor.from_config(config) as dop_processor:
                for pose_idx, pose in enumerate(pose_list):
                    # update pose and take new line image; write directly to output array
                    _, new_coverage, new_feats = self.set_pose(pose).take_line_img(dop_processor, active_sensors, out_array=img_out[:, :, pose_idx, :], config=config, feat_finder=feat_finder)
                    coverage_geoms.append(new_coverage)
                    found_feats += new_feats

            coverage = unary_union(coverage_geoms)  # union of ground track coverage of individual scan lines
            return img_out, coverage, found_feats

    def chunky_swath(self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
        &#34;&#34;&#34;
        Acquire image in chunks of pre-set approximate size, and store each chunk in a temp file to prevent RAM/CPU chache from filling up.

        Parameters
        ----------
        pose_list : list of Cam_pose
            List of poses to be used for the individual line images.
        active_sensors : list of Sensor, optional
            sensor objects to be used for the image. If not given, all sensors
            are used.
        out_array : np.ndarray, optional
            output array for in-place writing. If not given, a new array is created.
        config : Config, optional
            Dict of config parameters. If not given, default parameters are used.
        feat_finder : Feature_finder, optional
            Feature_finder instance used to detect GCPs.

        Returns
        -------
        img_out : np.array
            array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).
        coverage : shapely.geoms.Polygon or MultiPolygon
            Polygon or collection of Polygons representing the ground track coverage.
        found_feats : list
            list of found GCPs.

        &#34;&#34;&#34;
        if active_sensors is None:
            active_sensors = self.sensors

        chunk_size = config[&#39;CHUNK_SIZE&#39;]
        num_lines = len(pose_list)                                           # height of output image

        num_bands = max([len(sensor.bands) for sensor in active_sensors])    # number of channels of output image
        num_pixels = max([sensor.pixels for sensor in active_sensors])       # width of output image

        lines_per_chunk = int(chunk_size / (num_bands * num_pixels))
        num_chunks = int(np.ceil(num_lines / lines_per_chunk))

        # split input parameters into chunks
        splits = [i * lines_per_chunk for i in range(num_chunks)]
        splits.append(num_lines)

        with Temp_handler.from_config(config) as temp_handler:
            # sequentially simulate chunks and store in temp files
            for i in range(num_chunks):
                temp_handler.save(self.take_swath_img_raw(pose_list[splits[i]:splits[i + 1]], active_sensors, None, config, feat_finder))

            # load partial results from temp files
            imgs, coverage_geoms, split_feats = zip(*temp_handler.load_all())

        if out_array is None:
            # create array containing output images for all sensors and bands
            img_out = np.full((len(active_sensors), num_bands, num_lines, num_pixels), np.NaN, np.uint8)
        else:
            img_out = out_array

        # write individual chunks to one output image
        for i in range(num_chunks):
            img_out[:, :, splits[i]:splits[i + 1], :] = imgs[i]

        coverage = unary_union(coverage_geoms)          # union of ground track coverage from individual chunks
        found_feats = chain.from_iterable(split_feats)  # compile detected GCPs into single list
        return img_out, coverage, found_feats

    def multithread_swath(self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
        &#34;&#34;&#34;
        Take image composed of line scans from specified poses using multithreading.
        If possible, use multiprocessing instead for better performance.

        Parameters
        ----------
        pose_list : list of Cam_pose
            List of poses to be used for the individual line images.
        active_sensors : list of Sensor, optional
            sensor objects to be used for the image. If not given, all sensors
            are used.
        out_array : np.ndarray, optional
            output array for in-place writing. If not given, a new array is created.
        config : Config, optional
            Dict of config parameters. If not given, default parameters are used.
        feat_finder : Feature_finder, optional
            Feature_finder instance used to detect GCPs.

        Returns
        -------
        img_out : np.array
            array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).
        coverage : shapely.geoms.Polygon or MultiPolygon
            Polygon or collection of Polygons representing the ground track coverage.
        found_feats : list
            list of found GCPs.

        &#34;&#34;&#34;
        if active_sensors is None:
            active_sensors = self.sensors

        num_threads = config[&#39;NUM_THREADS&#39;]
        num_lines = len(pose_list)                                           # height of output image

        if out_array is None:
            num_bands = max([len(sensor.bands) for sensor in active_sensors])    # number of channels of output image
            num_pixels = max([sensor.pixels for sensor in active_sensors])       # width if output image

            # create array containing output images for all sensors and bands
            img_out = np.full((len(active_sensors), num_bands, num_lines, num_pixels), np.NaN, np.uint8)
        else:
            img_out = out_array

        # split input parameters into chunks (one per process)
        split_len = int(num_lines / num_threads)
        splits = [i * split_len for i in range(num_threads)]
        splits.append(num_lines)

        split_args = [(pose_list[splits[i]:splits[i + 1]], active_sensors, img_out[:, :, splits[i]:splits[i + 1], :], config, feat_finder)
                      for i in range(num_threads)]

        # pool of threads
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            split_results = executor.map(lambda args: self.take_swath_img_raw(*args), split_args)

        _, coverage_geoms, split_feats = zip(*split_results)
        coverage = unary_union(coverage_geoms)          # union of ground track coverage from individual threads
        found_feats = chain.from_iterable(split_feats)  # compile detected GCPs into single list
        return img_out, coverage, found_feats

    def multiprocess_swath(self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
        &#34;&#34;&#34;
        Take image composed of line scans from specified poses using multiprocessing.
        Note that on Windows, the script running the simulation must be guarded by if __name__ == &#39;__main__&#39;

        Parameters
        ----------
        pose_list : list of Cam_pose
            List of poses to be used for the individual line images.
        active_sensors : list of Sensor, optional
            sensor objects to be used for the image. If not given, all sensors
            are used.
        out_array : np.ndarray, optional
            output array for in-place writing. If not given, a new array is created.
        config : Config, optional
            Dict of config parameters. If not given, default parameters are used.
        feat_finder : Feature_finder, optional
            Feature_finder instance used to detect GCPs.

        Returns
        -------
        img_out : np.array
            array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).
        coverage : shapely.geoms.Polygon or MultiPolygon
            Polygon or collection of Polygons representing the ground track coverage.
        found_feats : list
            list of found GCPs.

        &#34;&#34;&#34;
        if active_sensors is None:
            active_sensors = self.sensors

        num_lines = len(pose_list)                                           # height of output image

        num_bands = max([len(sensor.bands) for sensor in active_sensors])    # number of channels of output image
        num_pixels = max([sensor.pixels for sensor in active_sensors])       # width of output image
        num_processes = config[&#39;NUM_PROCESSES&#39;]

        # split input parameters into chunks (one per process)
        split_len = int(num_lines / num_processes)
        splits = [i * split_len for i in range(num_processes)]
        splits.append(num_lines)

        split_args = [(pose_list[splits[i]:splits[i + 1]], active_sensors, None, config, feat_finder) for i in range(num_processes)]

        # pool of processes
        with mp.Pool() as pool:
            split_results = pool.starmap(self.take_swath_img_raw, split_args)

        imgs, coverage_geoms, split_feats = zip(*split_results)

        if out_array is None:
            # create array containing output images for all sensors and bands
            img_out = np.full((len(active_sensors), num_bands, num_lines, num_pixels), np.NaN, np.uint8)
        else:
            img_out = out_array

        # write to output image
        for i, img in enumerate(imgs):
            img_out[:, :, splits[i]:splits[i + 1], :] = img

        coverage = unary_union(coverage_geoms)          # union of ground track coverage from individual processes
        found_feats = chain.from_iterable(split_feats)  # compile detected GCPs into single list
        return img_out, coverage, found_feats

    def take_swath_img_raw(self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
        &#34;&#34;&#34;
        Take image composed of line scans from specified poses, without any degradation effects.
        Maps arguments to the corresponding Sim_mode.

        Parameters
        ----------
         pose_list : list of Cam_pose
             List of poses to be used for the individual line images.
         active_sensors : list of Sensor, optional
             sensor objects to be used for the image. If not given, all sensors
             are used.
         out_array : np.ndarray, optional
             output array for in-place writing. If not given, a new array is created.
        config : Config, optional
             Config dict containing parameters for the simulation run. If not provided, default parameters are used.
        feat_finder : Feature_finder, optional
            Feature_finder instance used to detect GCPs.

        Returns
        -------
        img_out : np.array
            array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).
        coverage : shapely.geoms.Polygon or MultiPolygon
            Polygon or collection of Polygons representing the ground track coverage.
        found_feats : list
            list of found GCPs.

        &#34;&#34;&#34;
        config = config.copy()
        sim_modes = config[&#39;SIM_MODES&#39;]
        sim_mode = sim_modes[0]
        config[&#39;SIM_MODES&#39;] = sim_modes[1:]

        if sim_mode == Sim_modes.DEFAULT:
            if sim_modes[1:]:
                raise ValueError(&#39;sim_modes must not specify additional simulation modes following a Sim_modes.DEFAULT entry&#39;)
            return self.default_swath(pose_list, active_sensors, out_array, config, feat_finder)

        elif sim_mode == Sim_modes.PROCESSES:
            return self.multiprocess_swath(pose_list, active_sensors, out_array, config, feat_finder)

        elif sim_mode == Sim_modes.THREADS:
            return self.multithread_swath(pose_list, active_sensors, out_array, config, feat_finder)

        elif sim_mode == Sim_modes.CHUNKS:
            return self.chunky_swath(pose_list, active_sensors, out_array, config, feat_finder)

        else:
            raise ValueError(&#39;sim_modes must only contain members of camera.Sim_modes&#39;)

    def simulate_swath(self, pose_list, active_sensors=None, out_array=None, PSF=None, config=get_config()):
        &#34;&#34;&#34;
        Simulate image composed of line scans from specified poses, and artificially degrade it as specified by PSF and Sensor.SNR.

        Parameters
        ----------
        pose_list : list of Cam_pose
            List of poses to be used for the individual line images.
        active_sensors : list of Sensor, optional
            sensor objects to be used for the image. If not given, all sensors
            are used.
        out_array : np.ndarray, optional
            output array for in-place writing. If not given, a new array is created.
        PSF : np.ndarray, optional
            Filter mask representing the point spread function, sampled at the pixel grid nodes. If not given, no filter is applied.
            If PSF.ndim == 2, all bands of all sensors are degraded with the same PSF.
            If PSF.ndim == 3, all bands of each sensor are degraded with the same PSF, and must have PSF.shape[0] == n_bands.
            If PSF.ndim == 4, every band of every sensor is degraded with an individual PSF, and must have PSF.shape[0] == sensors, PSF.shape[1] == n_bands.
        config : Config, optional
            Config dict containing parameters for the simulation run. If not provided, default parameters are used.

        Returns
        -------
        img_out : np.array
            array of simulated images after degradation according to config, shape (n_sensors, n_bands, n_lines, n_pixels).
        coverage : shapely.geoms.Polygon or MultiPolygon
            Polygon or collection of Polygons representing the ground track coverage.
        found_feats : list
            list of found GCPs.
        img_raw : np.array
            array of simulated images without added filter/noise, shape (n_sensors, n_bands, n_lines, n_pixels).

        &#34;&#34;&#34;
        if config[&#39;FIND_FEATURES&#39;]:
            feat_finder = Feature_finder.from_config(config)
        else:
            feat_finder = None

        img_raw, coverage, found_feats = self.take_swath_img_raw(pose_list, active_sensors, out_array, config, feat_finder)

        if config[&#39;NOISY&#39;] or (PSF is not None):
            SNR = np.array([sensor.SNRs for sensor in self.sensors])
            img_out = Camera.postprocess(img_raw, PSF, SNR, config)
        else:
            img_out = img_raw

        return img_out, coverage, found_feats, img_raw

    def postprocess(img_raw, PSF=None, SNR=None, config=get_config()):
        &#34;&#34;&#34;
        Artificially degrade (filter and noisify) simulated image.

        Parameters
        ----------
        img_raw : np.array
            array of simulated images without added filter/noise, shape (n_sensors, n_bands, n_lines, n_pixels).
        PSF : np.ndarray, optional
            Filter mask representing the point spread function, sampled at the pixel grid nodes. If not given, no filter is applied.
            If PSF.ndim == 2, all bands of all sensors are degraded with the same PSF.
            If PSF.ndim == 3, all bands of each sensor are degraded with the same PSF, and must have PSF.shape[0] == n_bands.
            If PSF.ndim == 4, every band of every sensor is degraded with an individual PSF, and must have PSF.shape[0] == sensors, PSF.shape[1] == n_bands.
        SNR : np.ndarray, optional
            Signal-to-noise ratios for addition of AWGN. Same conventions for shape as PSF. If not given, no noise is added.
        config : Config, optional
            Config dict containing parameters for the simulation run. If not given, default parameters are used.

        Returns
        -------
        img_out : np.array
            array of simulated images after degradation, shape (n_sensors, n_bands, n_lines, n_pixels).

        &#34;&#34;&#34;
        img_out = img_raw.copy()

        # apply PSF
        if PSF is not None:
            while PSF.ndim &lt; img_out.ndim:
                PSF = PSF[None, :]

            if PSF.shape[0] != img_out.shape[0]:
                PSF = np.repeat(PSF, img_out.shape[0], axis=0)

            if PSF.shape[1] != img_out.shape[1]:
                PSF = np.repeat(PSF, img_out.shape[1], axis=1)

            for sensor_idx in range(img_out.shape[0]):
                for band_idx in range(img_out.shape[1]):
                    img_out[sensor_idx, band_idx, :, :] = convolve2d(img_out[sensor_idx, band_idx, :, :], PSF[sensor_idx, band_idx, :, :], mode=&#39;same&#39;, boundary=&#39;symm&#39;)

        # noise
        if config[&#39;NOISY&#39;] and (SNR is not None):
            while SNR.ndim &lt; img_out.ndim - 2:
                SNR = SNR[None, :]

            if SNR.shape[0] != img_out.shape[0]:
                SNR = np.repeat(SNR, img_out.shape[0], axis=0)

            if SNR.shape[1] != img_out.shape[1]:
                SNR = np.repeat(SNR, img_out.shape[1], axis=1)

            noise = np.empty(img_out.shape, dtype=float)

            for sensor_idx in range(img_out.shape[0]):
                for band_idx in range(img_out.shape[1]):
                    sigma = np.mean(img_raw[sensor_idx, band_idx, :, :][np.where(img_raw[sensor_idx, band_idx, :, :])]) / SNR[sensor_idx, band_idx]
                    noise[sensor_idx, band_idx, :, :] = np.random.normal(0, sigma, img_raw[sensor_idx, band_idx, :, :].shape)   # independent noise for each band

            img_out = np.clip((img_out.astype(float) + noise), 0, 255).astype(np.uint8)

        # preserve nodata entries
        img_out = np.where(img_raw, img_out, 0)
        return img_out


class Sensor:
    &#34;&#34;&#34;
    Sensor object with own geometry and recorded bands.

    Parameters
    ----------
    name_str : string
        used as sensor name
    bands : tuple of int
        indices of recorded bands from input image file
    interior_orientation : Interior_orientation
        interior parameters of the camera
    pixels : int
        number of pixels in the line sensor
    px_size : float
        size of one pixel on the sensor
    SNRs : np.ndarray
        array containing signal-to-noise ratio of each band. Must have same length as bands

    Returns
    -------
    sensor : Sensor
        a new Sensor instance

    &#34;&#34;&#34;

    def __init__(self, name_str, bands, interior_orientation, pixels, px_size, SNRs):
        self.name = name_str
        self.bands = bands
        self.SNRs = np.array(SNRs)
        if self.SNRs.size != len(self.bands) and self.SNRs.size != 1:
            raise ValueError(&#39;Specify one SNR per band, or one SNR to be used for all bands&#39;)
        self.interior_orientation = interior_orientation
        self.pixels = pixels
        self.px_size = px_size
        self.pose = None
        self.prev_pose = None
        self.prev_corners_XY = None
        self.px_corners_xy = self.get_px_corners()
        return

    def get_px_corners(self):
        &#34;&#34;&#34;
        Compute location of pixel corners in image coordinates.

        Returns
        -------
        corners_xy : np.ndarray of float
            coordinates of all pixel corners, shape (2, self.pixels + 1, 1).
            corners_xy[0, :, :] contains x values, corners_xy[1, :, :] y values.
            Corners are sorted according to ascending x.

        &#34;&#34;&#34;
        # horizontal positions of pixel corners in pixel coordinates
        px_cs = np.linspace(-.5, self.pixels + .5, self.pixels + 1)

        # vertical position of pixel corners in pixel coordinates (zero by definition)
        px_rs = np.zeros(px_cs.shape)

        # merge r and c values
        corners_rc = np.stack([px_rs, px_cs], axis=0)

        corners_xy = self.pixels_to_imgcoord(corners_rc)
        return corners_xy

    def pixels_to_imgcoord(self, coords_rc):
        &#34;&#34;&#34;
        Compute image coordinates of a location in output image pixel coordinate system.

        Parameters
        ----------
        coords_rc : np.ndarray of float
            array of shape (2, ...), where coords_rc[0] contains only r coordinates, coords_rc[1] contains corresponding c coordinates.

        Returns
        -------
        coords_xy : np.ndarray of float
            array of shape coords_rc.shape, where coords_xy[0] contains only x coordinates, coords_xy[1] contains corresponding y coordinates.

        &#34;&#34;&#34;
        # r = coords_rc[0]
        # c = coords_rc[1]

        x = (coords_rc[1] + 0.5) * self.px_size - self.px_size * self.pixels / 2
        y = - coords_rc[0] * self.px_size
        return np.array([x, y])

    def get_object_coordinates(self, img_coord, Z_terrain=0, pose=None):
        &#34;&#34;&#34;
        Compute projection of image coordinates onto terrain in current pose.

        Parameters
        ----------
        img_coord : np.ndarray of float
            array of shape (2, ...), where img_coord[0] contains only x coordinates, img_coord[1] contains corresponding y coordinates.
        Z_terrain : float, optional
            vertical height of terrain at position (X,Y). The default is 0.
        pose : Cam_pose, optional
            pose representing exterior orientation to be used for calculation. If not given, current self.pose of the sensor is used.

        Returns
        -------
        coords_XY: np.ndarray of float
            array of shape img_coord.shape, where coords_XY[0] contains only X coordinates, coords_XY[1] contains corresponding Y coordinates.

        &#34;&#34;&#34;
        if pose is None:
            pose = self.pose

        delta_x = self.interior_orientation.x0 - img_coord[0]
        delta_y = self.interior_orientation.y0 - img_coord[1]

        denominator = pose.R[2, 0] * delta_x + pose.R[2, 1] * delta_y + pose.R[2, 2] * self.interior_orientation.c
        const_factor = (Z_terrain - pose.XYZ_0[2]) / denominator

        X = pose.XYZ_0[0] + const_factor * \
            (pose.R[0, 0] * delta_x + pose.R[0, 1] * delta_y - pose.R[0, 2] * self.interior_orientation.c)
        Y = pose.XYZ_0[1] + const_factor * \
            (pose.R[1, 0] * delta_x + pose.R[1, 1] * delta_y - pose.R[1, 2] * self.interior_orientation.c)
        return np.stack([X, Y])

    def take_line_img(self, dop_processor, config=get_config(), feat_finder=None):
        &#34;&#34;&#34;
        Acquire a single line image from current camera pose.

        Parameters
        ----------
        dop_processor : DOP_processor
            DOP_processor instance used to read data from DOP.
        config : Config, optional
            Dict of config parameters. If not given, default parameters are used.
        feat_finder : Feature_finder, optional
            Feature_finder instance used to detect GCPs.

        Returns
        -------
        img_out : np.array
            output images for all bands in self.bands, has shape (len(self.bands), 1, self.pixels).
        coverage : shapely.geoms.Polygon or MultiPolygon
            Polygon or collection of Polygons representing the ground track coverage.
         found_feats : list
             list of found GCPs.

        &#34;&#34;&#34;
        img_out = np.zeros((len(self.bands), self.pixels), np.uint8)
        coverage_list = list()
        found_feats = list()

        new_corners_XY = self.get_object_coordinates(self.px_corners_xy, Z_terrain=config[&#39;MEAN_TERRAIN_HEIGHT&#39;])
        if (not self.prev_pose == self.pose.previous) or (self.prev_corners_XY is None):
            if not self.pose.previous:
                return img_out, Polygon(), []
            self.prev_corners_XY = self.get_object_coordinates(self.px_corners_xy, Z_terrain=config[&#39;MEAN_TERRAIN_HEIGHT&#39;], pose=self.pose.previous)

        for pixel in range(self.pixels):
            # pixel corners in object (XY) coordinates
            pixel_corners_XY = [tuple(new_corners_XY[:, pixel]),
                                tuple(self.prev_corners_XY[:, pixel]),
                                tuple(self.prev_corners_XY[:, pixel + 1]),
                                tuple(new_corners_XY[:, pixel + 1])]

            is_success, sample, new_coverage = dop_processor.sample_area(pixel_corners_XY, self.bands)

            if feat_finder:
                found_feats += feat_finder.check(new_coverage, pixel_corners_XY, self.pose.idx, pixel, self.name, self.pose)

            # update ground track coverage with new pixel area
            coverage_list.append(new_coverage)

            if not is_success:
                img_out[:, pixel] = 0   # write 0 (no data) to output image
                continue

            # take mean value of all contained DOP raster points (for each band) and write to output image
            img_out[:, pixel] = sample

        self.prev_pose = self.pose              # update previous pose
        self.prev_corners_XY = new_corners_XY   # update projected corner coordinates
        coverage = unary_union(coverage_list)
        return img_out, coverage, found_feats


class Interior_orientation:
    &#34;&#34;&#34;
    Interior_orientation object to specify location of image principal point.

    Parameters
    ----------
    x0 : float
        principal point x offset in mm
    y0 : float
        principal point y offset in mm
    c : float
        camera focal length in mm

    Returns
    -------
    interior : Interior_orientation
        a new Interior_orientation instance.

    &#34;&#34;&#34;

    def __init__(self, x0, y0, c):
        self.x0 = x0
        self.y0 = y0
        self.c = c
        return


class Cam_pose:
    &#34;&#34;&#34;
    Cam_pose object to specify camera exterior orientation.

    Parameters
    ----------
    idx : int
        index of this pose in the orbit.
    coords_obj: tuple of float
        position of camera in object coordinates in (X0, Y0, Z0) format.
    attitude : tuple of float
        (alpha_y, alpha_x, alpha_z) angles from nominal orbit definition, in rad.
    deviate_angles: tuple of float, optional
        deviatory rotation angles from nominal orbit in (yaw, pitch, roll) format. Defaults to (0, 0, 0).

    Returns
    -------
    pose : Cam_pose
        a new Cam_pose instance.

    &#34;&#34;&#34;
    # transformer from EPSG:25832 XYZ to ETRS89 lat/lon coordinates
    crs_obj = pyproj.CRS(&#34;epsg:25832&#34;)          # XYZ object coordinates
    lla = pyproj.CRS(&#34;epsg:4258&#34;)               # ETRS89 with GRS1980 ellipsoid
    obj_to_lla = pyproj.transformer.Transformer.from_crs(crs_obj, lla)

    # rotation matrix from xyz image to satellite vehicle coordinate axes
    R_img2sat = np.array([[0, 1, 0], [1, 0, 0], [0, 0, -1]])

    def __init__(self, idx, coords_obj, attitude, deviate_angles=None):
        self.idx = idx
        self.XYZ_0 = np.array(coords_obj)
        self.previous = None
        alpha_y, alpha_x, alpha_z = attitude

        # rotation matrix from ECEF to EPSG:25832 object coordinates
        lat, lon, _ = Cam_pose.obj_to_lla.transform(self.XYZ_0[0], self.XYZ_0[1], self.XYZ_0[2], radians=True)
        R_ecef2obj = np.array([[-np.sin(lon), np.cos(lon), 0],
                               [-np.sin(lat) * np.cos(lon), -np.sin(lat) * np.sin(lon), np.cos(lat)],
                               [np.cos(lat) * np.cos(lon), np.cos(lat) * np.sin(lon), np.sin(lat)]])

        # rotation matrix from satellite vehicle to ECEF coordinates
        R_sat2ecef = np.matmul(rotation_z(alpha_z), np.matmul(rotation_x(alpha_x), rotation_y(alpha_y)))

        if deviate_angles:
            # roll: &#34;right wing down&#34; positive
            # pitch: &#34;nose up&#34; positive
            # yaw: &#34;turn right&#34; positive
            # defined in satellite vehicle system
            yaw, pitch, roll = deviate_angles
            R_deviate = np.matmul(rotation_x(roll), np.matmul(rotation_y(pitch), rotation_z(yaw)))
        else:
            R_deviate = np.identity(3)

        # complete rotation matrix
        self.R = np.matmul(R_ecef2obj, np.matmul(R_sat2ecef, np.matmul(R_deviate, Cam_pose.R_img2sat)))
        return

    def __eq__(self, other):
        if isinstance(other, Cam_pose):
            return self.idx == other.idx and np.all(self.XYZ_0 == other.XYZ_0) and np.all(self.R == other.R)
        return False

    def copy(self):
        copy = object.__new__(Cam_pose)
        copy.idx = self.idx
        copy.previous = None
        copy.XYZ_0 = self.XYZ_0.copy()
        copy.R = self.R
        return copy

    def set_previous(self, prev_pose):
        self.previous = prev_pose.copy()
        return self</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="satcamsim.camera.Cam_pose"><code class="flex name class">
<span>class <span class="ident">Cam_pose</span></span>
<span>(</span><span>idx, coords_obj, attitude, deviate_angles=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Cam_pose object to specify camera exterior orientation.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>idx</code></strong> :&ensp;<code>int</code></dt>
<dd>index of this pose in the orbit.</dd>
<dt><strong><code>coords_obj</code></strong> :&ensp;<code>tuple</code> of <code>float</code></dt>
<dd>position of camera in object coordinates in (X0, Y0, Z0) format.</dd>
<dt><strong><code>attitude</code></strong> :&ensp;<code>tuple</code> of <code>float</code></dt>
<dd>(alpha_y, alpha_x, alpha_z) angles from nominal orbit definition, in rad.</dd>
<dt><strong><code>deviate_angles</code></strong> :&ensp;<code>tuple</code> of <code>float</code>, optional</dt>
<dd>deviatory rotation angles from nominal orbit in (yaw, pitch, roll) format. Defaults to (0, 0, 0).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>pose</code></strong> :&ensp;<code><a title="satcamsim.camera.Cam_pose" href="#satcamsim.camera.Cam_pose">Cam_pose</a></code></dt>
<dd>a new Cam_pose instance.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Cam_pose:
    &#34;&#34;&#34;
    Cam_pose object to specify camera exterior orientation.

    Parameters
    ----------
    idx : int
        index of this pose in the orbit.
    coords_obj: tuple of float
        position of camera in object coordinates in (X0, Y0, Z0) format.
    attitude : tuple of float
        (alpha_y, alpha_x, alpha_z) angles from nominal orbit definition, in rad.
    deviate_angles: tuple of float, optional
        deviatory rotation angles from nominal orbit in (yaw, pitch, roll) format. Defaults to (0, 0, 0).

    Returns
    -------
    pose : Cam_pose
        a new Cam_pose instance.

    &#34;&#34;&#34;
    # transformer from EPSG:25832 XYZ to ETRS89 lat/lon coordinates
    crs_obj = pyproj.CRS(&#34;epsg:25832&#34;)          # XYZ object coordinates
    lla = pyproj.CRS(&#34;epsg:4258&#34;)               # ETRS89 with GRS1980 ellipsoid
    obj_to_lla = pyproj.transformer.Transformer.from_crs(crs_obj, lla)

    # rotation matrix from xyz image to satellite vehicle coordinate axes
    R_img2sat = np.array([[0, 1, 0], [1, 0, 0], [0, 0, -1]])

    def __init__(self, idx, coords_obj, attitude, deviate_angles=None):
        self.idx = idx
        self.XYZ_0 = np.array(coords_obj)
        self.previous = None
        alpha_y, alpha_x, alpha_z = attitude

        # rotation matrix from ECEF to EPSG:25832 object coordinates
        lat, lon, _ = Cam_pose.obj_to_lla.transform(self.XYZ_0[0], self.XYZ_0[1], self.XYZ_0[2], radians=True)
        R_ecef2obj = np.array([[-np.sin(lon), np.cos(lon), 0],
                               [-np.sin(lat) * np.cos(lon), -np.sin(lat) * np.sin(lon), np.cos(lat)],
                               [np.cos(lat) * np.cos(lon), np.cos(lat) * np.sin(lon), np.sin(lat)]])

        # rotation matrix from satellite vehicle to ECEF coordinates
        R_sat2ecef = np.matmul(rotation_z(alpha_z), np.matmul(rotation_x(alpha_x), rotation_y(alpha_y)))

        if deviate_angles:
            # roll: &#34;right wing down&#34; positive
            # pitch: &#34;nose up&#34; positive
            # yaw: &#34;turn right&#34; positive
            # defined in satellite vehicle system
            yaw, pitch, roll = deviate_angles
            R_deviate = np.matmul(rotation_x(roll), np.matmul(rotation_y(pitch), rotation_z(yaw)))
        else:
            R_deviate = np.identity(3)

        # complete rotation matrix
        self.R = np.matmul(R_ecef2obj, np.matmul(R_sat2ecef, np.matmul(R_deviate, Cam_pose.R_img2sat)))
        return

    def __eq__(self, other):
        if isinstance(other, Cam_pose):
            return self.idx == other.idx and np.all(self.XYZ_0 == other.XYZ_0) and np.all(self.R == other.R)
        return False

    def copy(self):
        copy = object.__new__(Cam_pose)
        copy.idx = self.idx
        copy.previous = None
        copy.XYZ_0 = self.XYZ_0.copy()
        copy.R = self.R
        return copy

    def set_previous(self, prev_pose):
        self.previous = prev_pose.copy()
        return self</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="satcamsim.camera.Cam_pose.R_img2sat"><code class="name">var <span class="ident">R_img2sat</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="satcamsim.camera.Cam_pose.crs_obj"><code class="name">var <span class="ident">crs_obj</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="satcamsim.camera.Cam_pose.lla"><code class="name">var <span class="ident">lla</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="satcamsim.camera.Cam_pose.obj_to_lla"><code class="name">var <span class="ident">obj_to_lla</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="satcamsim.camera.Cam_pose.copy"><code class="name flex">
<span>def <span class="ident">copy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def copy(self):
    copy = object.__new__(Cam_pose)
    copy.idx = self.idx
    copy.previous = None
    copy.XYZ_0 = self.XYZ_0.copy()
    copy.R = self.R
    return copy</code></pre>
</details>
</dd>
<dt id="satcamsim.camera.Cam_pose.set_previous"><code class="name flex">
<span>def <span class="ident">set_previous</span></span>(<span>self, prev_pose)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_previous(self, prev_pose):
    self.previous = prev_pose.copy()
    return self</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="satcamsim.camera.Camera"><code class="flex name class">
<span>class <span class="ident">Camera</span></span>
</code></dt>
<dd>
<div class="desc"><p>Camera object with pose and sensors attributes.</p>
<h2 id="returns">Returns</h2>
<p>None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Camera:
    &#34;&#34;&#34;
    Camera object with pose and sensors attributes.

    Returns
    -------
    None.

    &#34;&#34;&#34;

    def __init__(self):
        self.sensors = []
        self.pose = None
        return

    def add_sensor(self, sensor):
        &#34;&#34;&#34;
        Append additional Sensor object to Camera&#39;s list of sensors.

        Parameters
        ----------
        sensor : Sensor
            sensor to be appended.

        Returns
        -------
        self : Camera
            updated camera instance.

        &#34;&#34;&#34;
        self.sensors.append(sensor)
        return self

    def set_pose(self, pose):
        &#34;&#34;&#34;
        Specify exterior orientation of camera.

        Parameters
        ----------
        pose : Cam_pose
            pose of the camera

        Returns
        -------
        self : Camera
            updated camera instance.
        &#34;&#34;&#34;
        self.pose = pose
        for sensor in self.sensors:
            sensor.pose = self.pose
        return self

    def take_line_img(self, dop_processor, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
        &#34;&#34;&#34;
        Acquire a single line image from the current pose using the specified sensors.

        Parameters
        ----------
        dop_processor : DOP_processor
            DOP_processor instance used to read data from DOP.
        active_sensors : list of Sensor, optional
            Sensor objects to be used for the image. If not given, all sensors
            are used.
        out_array : np.ndarray, optional
            output array for in-place writing. If not given, a new array is created.
        config : Config, optional
            Dict of config parameters. If not given, default parameters are used.
        feat_finder : Feature_finder, optional
            Feature_finder instance used to detect GCPs.

        Returns
        -------
        img_out : np.ndarray of np.uint8
            array of simulated images, shape (n_sensors, n_bands, 1, n_pixels).
        coverage : Polygon or MultiPolygon
            Polygon or collection of Polygons representing the ground track coverage.
        found_feats : list
            list of found GCPs.

        &#34;&#34;&#34;
        if active_sensors is None:
            active_sensors = self.sensors

        if out_array is None:
            num_bands = max([len(sensor.bands) for sensor in active_sensors])
            num_pixels = max([sensor.pixels for sensor in active_sensors])
            img_out = np.full((len(active_sensors), num_bands, num_pixels), np.NaN, np.uint8)
        else:
            img_out = out_array

        coverage_geoms = list()
        found_feats = list()

        for sensor_idx, sensor in enumerate(active_sensors):
            # take line images with all specified sensors
            img_out[sensor_idx, :, :], new_coverage, new_feats = sensor.take_line_img(dop_processor, config, feat_finder)

            # add ground covered in new line image
            coverage_geoms.append(new_coverage)
            found_feats += new_feats

        coverage = unary_union(coverage_geoms)  # union of ground track coverage of individual pixels
        return img_out, coverage, found_feats

    def default_swath(self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
        &#34;&#34;&#34;
        Take image composed of line scans from specified poses.

        Parameters
        ----------
        pose_list : list of Cam_pose
            List of poses to be used for the individual line images.
        active_sensors : list of Sensor, optional
            sensor objects to be used for the image. If not given, all sensors
            are used.
        out_array : np.ndarray, optional
            output array for in-place writing. If not given, a new array is created.
        config : Config, optional
            Dict of config parameters. If not given, default parameters are used.
        feat_finder : Feature_finder, optional
            Feature_finder instance used to detect GCPs.

        Returns
        -------
        img_out : np.array
            array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).
        coverage : shapely.geoms.Polygon or MultiPolygon
            Polygon or collection of Polygons representing the ground track coverage.
        found_feats : list
            list of found GCPs.

        &#34;&#34;&#34;
        with rasterio.Env() as rio_env:
            if active_sensors is None:
                active_sensors = self.sensors

            num_lines = len(pose_list)                                           # height of output image

            if out_array is None:
                num_bands = max([len(sensor.bands) for sensor in active_sensors])    # number of channels of output image
                num_pixels = max([sensor.pixels for sensor in active_sensors])       # width if output image

                # create array containing output images for all sensors and bands
                img_out = np.full((len(active_sensors), num_bands, num_lines, num_pixels), np.NaN, np.uint8)
            else:
                img_out = out_array

            coverage_geoms = list()
            found_feats = list()

            with DOP_processor.from_config(config) as dop_processor:
                for pose_idx, pose in enumerate(pose_list):
                    # update pose and take new line image; write directly to output array
                    _, new_coverage, new_feats = self.set_pose(pose).take_line_img(dop_processor, active_sensors, out_array=img_out[:, :, pose_idx, :], config=config, feat_finder=feat_finder)
                    coverage_geoms.append(new_coverage)
                    found_feats += new_feats

            coverage = unary_union(coverage_geoms)  # union of ground track coverage of individual scan lines
            return img_out, coverage, found_feats

    def chunky_swath(self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
        &#34;&#34;&#34;
        Acquire image in chunks of pre-set approximate size, and store each chunk in a temp file to prevent RAM/CPU chache from filling up.

        Parameters
        ----------
        pose_list : list of Cam_pose
            List of poses to be used for the individual line images.
        active_sensors : list of Sensor, optional
            sensor objects to be used for the image. If not given, all sensors
            are used.
        out_array : np.ndarray, optional
            output array for in-place writing. If not given, a new array is created.
        config : Config, optional
            Dict of config parameters. If not given, default parameters are used.
        feat_finder : Feature_finder, optional
            Feature_finder instance used to detect GCPs.

        Returns
        -------
        img_out : np.array
            array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).
        coverage : shapely.geoms.Polygon or MultiPolygon
            Polygon or collection of Polygons representing the ground track coverage.
        found_feats : list
            list of found GCPs.

        &#34;&#34;&#34;
        if active_sensors is None:
            active_sensors = self.sensors

        chunk_size = config[&#39;CHUNK_SIZE&#39;]
        num_lines = len(pose_list)                                           # height of output image

        num_bands = max([len(sensor.bands) for sensor in active_sensors])    # number of channels of output image
        num_pixels = max([sensor.pixels for sensor in active_sensors])       # width of output image

        lines_per_chunk = int(chunk_size / (num_bands * num_pixels))
        num_chunks = int(np.ceil(num_lines / lines_per_chunk))

        # split input parameters into chunks
        splits = [i * lines_per_chunk for i in range(num_chunks)]
        splits.append(num_lines)

        with Temp_handler.from_config(config) as temp_handler:
            # sequentially simulate chunks and store in temp files
            for i in range(num_chunks):
                temp_handler.save(self.take_swath_img_raw(pose_list[splits[i]:splits[i + 1]], active_sensors, None, config, feat_finder))

            # load partial results from temp files
            imgs, coverage_geoms, split_feats = zip(*temp_handler.load_all())

        if out_array is None:
            # create array containing output images for all sensors and bands
            img_out = np.full((len(active_sensors), num_bands, num_lines, num_pixels), np.NaN, np.uint8)
        else:
            img_out = out_array

        # write individual chunks to one output image
        for i in range(num_chunks):
            img_out[:, :, splits[i]:splits[i + 1], :] = imgs[i]

        coverage = unary_union(coverage_geoms)          # union of ground track coverage from individual chunks
        found_feats = chain.from_iterable(split_feats)  # compile detected GCPs into single list
        return img_out, coverage, found_feats

    def multithread_swath(self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
        &#34;&#34;&#34;
        Take image composed of line scans from specified poses using multithreading.
        If possible, use multiprocessing instead for better performance.

        Parameters
        ----------
        pose_list : list of Cam_pose
            List of poses to be used for the individual line images.
        active_sensors : list of Sensor, optional
            sensor objects to be used for the image. If not given, all sensors
            are used.
        out_array : np.ndarray, optional
            output array for in-place writing. If not given, a new array is created.
        config : Config, optional
            Dict of config parameters. If not given, default parameters are used.
        feat_finder : Feature_finder, optional
            Feature_finder instance used to detect GCPs.

        Returns
        -------
        img_out : np.array
            array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).
        coverage : shapely.geoms.Polygon or MultiPolygon
            Polygon or collection of Polygons representing the ground track coverage.
        found_feats : list
            list of found GCPs.

        &#34;&#34;&#34;
        if active_sensors is None:
            active_sensors = self.sensors

        num_threads = config[&#39;NUM_THREADS&#39;]
        num_lines = len(pose_list)                                           # height of output image

        if out_array is None:
            num_bands = max([len(sensor.bands) for sensor in active_sensors])    # number of channels of output image
            num_pixels = max([sensor.pixels for sensor in active_sensors])       # width if output image

            # create array containing output images for all sensors and bands
            img_out = np.full((len(active_sensors), num_bands, num_lines, num_pixels), np.NaN, np.uint8)
        else:
            img_out = out_array

        # split input parameters into chunks (one per process)
        split_len = int(num_lines / num_threads)
        splits = [i * split_len for i in range(num_threads)]
        splits.append(num_lines)

        split_args = [(pose_list[splits[i]:splits[i + 1]], active_sensors, img_out[:, :, splits[i]:splits[i + 1], :], config, feat_finder)
                      for i in range(num_threads)]

        # pool of threads
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            split_results = executor.map(lambda args: self.take_swath_img_raw(*args), split_args)

        _, coverage_geoms, split_feats = zip(*split_results)
        coverage = unary_union(coverage_geoms)          # union of ground track coverage from individual threads
        found_feats = chain.from_iterable(split_feats)  # compile detected GCPs into single list
        return img_out, coverage, found_feats

    def multiprocess_swath(self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
        &#34;&#34;&#34;
        Take image composed of line scans from specified poses using multiprocessing.
        Note that on Windows, the script running the simulation must be guarded by if __name__ == &#39;__main__&#39;

        Parameters
        ----------
        pose_list : list of Cam_pose
            List of poses to be used for the individual line images.
        active_sensors : list of Sensor, optional
            sensor objects to be used for the image. If not given, all sensors
            are used.
        out_array : np.ndarray, optional
            output array for in-place writing. If not given, a new array is created.
        config : Config, optional
            Dict of config parameters. If not given, default parameters are used.
        feat_finder : Feature_finder, optional
            Feature_finder instance used to detect GCPs.

        Returns
        -------
        img_out : np.array
            array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).
        coverage : shapely.geoms.Polygon or MultiPolygon
            Polygon or collection of Polygons representing the ground track coverage.
        found_feats : list
            list of found GCPs.

        &#34;&#34;&#34;
        if active_sensors is None:
            active_sensors = self.sensors

        num_lines = len(pose_list)                                           # height of output image

        num_bands = max([len(sensor.bands) for sensor in active_sensors])    # number of channels of output image
        num_pixels = max([sensor.pixels for sensor in active_sensors])       # width of output image
        num_processes = config[&#39;NUM_PROCESSES&#39;]

        # split input parameters into chunks (one per process)
        split_len = int(num_lines / num_processes)
        splits = [i * split_len for i in range(num_processes)]
        splits.append(num_lines)

        split_args = [(pose_list[splits[i]:splits[i + 1]], active_sensors, None, config, feat_finder) for i in range(num_processes)]

        # pool of processes
        with mp.Pool() as pool:
            split_results = pool.starmap(self.take_swath_img_raw, split_args)

        imgs, coverage_geoms, split_feats = zip(*split_results)

        if out_array is None:
            # create array containing output images for all sensors and bands
            img_out = np.full((len(active_sensors), num_bands, num_lines, num_pixels), np.NaN, np.uint8)
        else:
            img_out = out_array

        # write to output image
        for i, img in enumerate(imgs):
            img_out[:, :, splits[i]:splits[i + 1], :] = img

        coverage = unary_union(coverage_geoms)          # union of ground track coverage from individual processes
        found_feats = chain.from_iterable(split_feats)  # compile detected GCPs into single list
        return img_out, coverage, found_feats

    def take_swath_img_raw(self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
        &#34;&#34;&#34;
        Take image composed of line scans from specified poses, without any degradation effects.
        Maps arguments to the corresponding Sim_mode.

        Parameters
        ----------
         pose_list : list of Cam_pose
             List of poses to be used for the individual line images.
         active_sensors : list of Sensor, optional
             sensor objects to be used for the image. If not given, all sensors
             are used.
         out_array : np.ndarray, optional
             output array for in-place writing. If not given, a new array is created.
        config : Config, optional
             Config dict containing parameters for the simulation run. If not provided, default parameters are used.
        feat_finder : Feature_finder, optional
            Feature_finder instance used to detect GCPs.

        Returns
        -------
        img_out : np.array
            array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).
        coverage : shapely.geoms.Polygon or MultiPolygon
            Polygon or collection of Polygons representing the ground track coverage.
        found_feats : list
            list of found GCPs.

        &#34;&#34;&#34;
        config = config.copy()
        sim_modes = config[&#39;SIM_MODES&#39;]
        sim_mode = sim_modes[0]
        config[&#39;SIM_MODES&#39;] = sim_modes[1:]

        if sim_mode == Sim_modes.DEFAULT:
            if sim_modes[1:]:
                raise ValueError(&#39;sim_modes must not specify additional simulation modes following a Sim_modes.DEFAULT entry&#39;)
            return self.default_swath(pose_list, active_sensors, out_array, config, feat_finder)

        elif sim_mode == Sim_modes.PROCESSES:
            return self.multiprocess_swath(pose_list, active_sensors, out_array, config, feat_finder)

        elif sim_mode == Sim_modes.THREADS:
            return self.multithread_swath(pose_list, active_sensors, out_array, config, feat_finder)

        elif sim_mode == Sim_modes.CHUNKS:
            return self.chunky_swath(pose_list, active_sensors, out_array, config, feat_finder)

        else:
            raise ValueError(&#39;sim_modes must only contain members of camera.Sim_modes&#39;)

    def simulate_swath(self, pose_list, active_sensors=None, out_array=None, PSF=None, config=get_config()):
        &#34;&#34;&#34;
        Simulate image composed of line scans from specified poses, and artificially degrade it as specified by PSF and Sensor.SNR.

        Parameters
        ----------
        pose_list : list of Cam_pose
            List of poses to be used for the individual line images.
        active_sensors : list of Sensor, optional
            sensor objects to be used for the image. If not given, all sensors
            are used.
        out_array : np.ndarray, optional
            output array for in-place writing. If not given, a new array is created.
        PSF : np.ndarray, optional
            Filter mask representing the point spread function, sampled at the pixel grid nodes. If not given, no filter is applied.
            If PSF.ndim == 2, all bands of all sensors are degraded with the same PSF.
            If PSF.ndim == 3, all bands of each sensor are degraded with the same PSF, and must have PSF.shape[0] == n_bands.
            If PSF.ndim == 4, every band of every sensor is degraded with an individual PSF, and must have PSF.shape[0] == sensors, PSF.shape[1] == n_bands.
        config : Config, optional
            Config dict containing parameters for the simulation run. If not provided, default parameters are used.

        Returns
        -------
        img_out : np.array
            array of simulated images after degradation according to config, shape (n_sensors, n_bands, n_lines, n_pixels).
        coverage : shapely.geoms.Polygon or MultiPolygon
            Polygon or collection of Polygons representing the ground track coverage.
        found_feats : list
            list of found GCPs.
        img_raw : np.array
            array of simulated images without added filter/noise, shape (n_sensors, n_bands, n_lines, n_pixels).

        &#34;&#34;&#34;
        if config[&#39;FIND_FEATURES&#39;]:
            feat_finder = Feature_finder.from_config(config)
        else:
            feat_finder = None

        img_raw, coverage, found_feats = self.take_swath_img_raw(pose_list, active_sensors, out_array, config, feat_finder)

        if config[&#39;NOISY&#39;] or (PSF is not None):
            SNR = np.array([sensor.SNRs for sensor in self.sensors])
            img_out = Camera.postprocess(img_raw, PSF, SNR, config)
        else:
            img_out = img_raw

        return img_out, coverage, found_feats, img_raw

    def postprocess(img_raw, PSF=None, SNR=None, config=get_config()):
        &#34;&#34;&#34;
        Artificially degrade (filter and noisify) simulated image.

        Parameters
        ----------
        img_raw : np.array
            array of simulated images without added filter/noise, shape (n_sensors, n_bands, n_lines, n_pixels).
        PSF : np.ndarray, optional
            Filter mask representing the point spread function, sampled at the pixel grid nodes. If not given, no filter is applied.
            If PSF.ndim == 2, all bands of all sensors are degraded with the same PSF.
            If PSF.ndim == 3, all bands of each sensor are degraded with the same PSF, and must have PSF.shape[0] == n_bands.
            If PSF.ndim == 4, every band of every sensor is degraded with an individual PSF, and must have PSF.shape[0] == sensors, PSF.shape[1] == n_bands.
        SNR : np.ndarray, optional
            Signal-to-noise ratios for addition of AWGN. Same conventions for shape as PSF. If not given, no noise is added.
        config : Config, optional
            Config dict containing parameters for the simulation run. If not given, default parameters are used.

        Returns
        -------
        img_out : np.array
            array of simulated images after degradation, shape (n_sensors, n_bands, n_lines, n_pixels).

        &#34;&#34;&#34;
        img_out = img_raw.copy()

        # apply PSF
        if PSF is not None:
            while PSF.ndim &lt; img_out.ndim:
                PSF = PSF[None, :]

            if PSF.shape[0] != img_out.shape[0]:
                PSF = np.repeat(PSF, img_out.shape[0], axis=0)

            if PSF.shape[1] != img_out.shape[1]:
                PSF = np.repeat(PSF, img_out.shape[1], axis=1)

            for sensor_idx in range(img_out.shape[0]):
                for band_idx in range(img_out.shape[1]):
                    img_out[sensor_idx, band_idx, :, :] = convolve2d(img_out[sensor_idx, band_idx, :, :], PSF[sensor_idx, band_idx, :, :], mode=&#39;same&#39;, boundary=&#39;symm&#39;)

        # noise
        if config[&#39;NOISY&#39;] and (SNR is not None):
            while SNR.ndim &lt; img_out.ndim - 2:
                SNR = SNR[None, :]

            if SNR.shape[0] != img_out.shape[0]:
                SNR = np.repeat(SNR, img_out.shape[0], axis=0)

            if SNR.shape[1] != img_out.shape[1]:
                SNR = np.repeat(SNR, img_out.shape[1], axis=1)

            noise = np.empty(img_out.shape, dtype=float)

            for sensor_idx in range(img_out.shape[0]):
                for band_idx in range(img_out.shape[1]):
                    sigma = np.mean(img_raw[sensor_idx, band_idx, :, :][np.where(img_raw[sensor_idx, band_idx, :, :])]) / SNR[sensor_idx, band_idx]
                    noise[sensor_idx, band_idx, :, :] = np.random.normal(0, sigma, img_raw[sensor_idx, band_idx, :, :].shape)   # independent noise for each band

            img_out = np.clip((img_out.astype(float) + noise), 0, 255).astype(np.uint8)

        # preserve nodata entries
        img_out = np.where(img_raw, img_out, 0)
        return img_out</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="satcamsim.camera.Camera.add_sensor"><code class="name flex">
<span>def <span class="ident">add_sensor</span></span>(<span>self, sensor)</span>
</code></dt>
<dd>
<div class="desc"><p>Append additional Sensor object to Camera's list of sensors.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>sensor</code></strong> :&ensp;<code><a title="satcamsim.camera.Sensor" href="#satcamsim.camera.Sensor">Sensor</a></code></dt>
<dd>sensor to be appended.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>self</code></strong> :&ensp;<code><a title="satcamsim.camera.Camera" href="#satcamsim.camera.Camera">Camera</a></code></dt>
<dd>updated camera instance.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_sensor(self, sensor):
    &#34;&#34;&#34;
    Append additional Sensor object to Camera&#39;s list of sensors.

    Parameters
    ----------
    sensor : Sensor
        sensor to be appended.

    Returns
    -------
    self : Camera
        updated camera instance.

    &#34;&#34;&#34;
    self.sensors.append(sensor)
    return self</code></pre>
</details>
</dd>
<dt id="satcamsim.camera.Camera.chunky_swath"><code class="name flex">
<span>def <span class="ident">chunky_swath</span></span>(<span>self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Acquire image in chunks of pre-set approximate size, and store each chunk in a temp file to prevent RAM/CPU chache from filling up.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>pose_list</code></strong> :&ensp;<code>list</code> of <code><a title="satcamsim.camera.Cam_pose" href="#satcamsim.camera.Cam_pose">Cam_pose</a></code></dt>
<dd>List of poses to be used for the individual line images.</dd>
<dt><strong><code>active_sensors</code></strong> :&ensp;<code>list</code> of <code><a title="satcamsim.camera.Sensor" href="#satcamsim.camera.Sensor">Sensor</a></code>, optional</dt>
<dd>sensor objects to be used for the image. If not given, all sensors
are used.</dd>
<dt><strong><code>out_array</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>output array for in-place writing. If not given, a new array is created.</dd>
<dt><strong><code>config</code></strong> :&ensp;<code>Config</code>, optional</dt>
<dd>Dict of config parameters. If not given, default parameters are used.</dd>
<dt><strong><code>feat_finder</code></strong> :&ensp;<code>Feature_finder</code>, optional</dt>
<dd>Feature_finder instance used to detect GCPs.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>img_out</code></strong> :&ensp;<code>np.array</code></dt>
<dd>array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).</dd>
<dt><strong><code>coverage</code></strong> :&ensp;<code>shapely.geoms.Polygon</code> or <code>MultiPolygon</code></dt>
<dd>Polygon or collection of Polygons representing the ground track coverage.</dd>
<dt><strong><code>found_feats</code></strong> :&ensp;<code>list</code></dt>
<dd>list of found GCPs.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def chunky_swath(self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
    &#34;&#34;&#34;
    Acquire image in chunks of pre-set approximate size, and store each chunk in a temp file to prevent RAM/CPU chache from filling up.

    Parameters
    ----------
    pose_list : list of Cam_pose
        List of poses to be used for the individual line images.
    active_sensors : list of Sensor, optional
        sensor objects to be used for the image. If not given, all sensors
        are used.
    out_array : np.ndarray, optional
        output array for in-place writing. If not given, a new array is created.
    config : Config, optional
        Dict of config parameters. If not given, default parameters are used.
    feat_finder : Feature_finder, optional
        Feature_finder instance used to detect GCPs.

    Returns
    -------
    img_out : np.array
        array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).
    coverage : shapely.geoms.Polygon or MultiPolygon
        Polygon or collection of Polygons representing the ground track coverage.
    found_feats : list
        list of found GCPs.

    &#34;&#34;&#34;
    if active_sensors is None:
        active_sensors = self.sensors

    chunk_size = config[&#39;CHUNK_SIZE&#39;]
    num_lines = len(pose_list)                                           # height of output image

    num_bands = max([len(sensor.bands) for sensor in active_sensors])    # number of channels of output image
    num_pixels = max([sensor.pixels for sensor in active_sensors])       # width of output image

    lines_per_chunk = int(chunk_size / (num_bands * num_pixels))
    num_chunks = int(np.ceil(num_lines / lines_per_chunk))

    # split input parameters into chunks
    splits = [i * lines_per_chunk for i in range(num_chunks)]
    splits.append(num_lines)

    with Temp_handler.from_config(config) as temp_handler:
        # sequentially simulate chunks and store in temp files
        for i in range(num_chunks):
            temp_handler.save(self.take_swath_img_raw(pose_list[splits[i]:splits[i + 1]], active_sensors, None, config, feat_finder))

        # load partial results from temp files
        imgs, coverage_geoms, split_feats = zip(*temp_handler.load_all())

    if out_array is None:
        # create array containing output images for all sensors and bands
        img_out = np.full((len(active_sensors), num_bands, num_lines, num_pixels), np.NaN, np.uint8)
    else:
        img_out = out_array

    # write individual chunks to one output image
    for i in range(num_chunks):
        img_out[:, :, splits[i]:splits[i + 1], :] = imgs[i]

    coverage = unary_union(coverage_geoms)          # union of ground track coverage from individual chunks
    found_feats = chain.from_iterable(split_feats)  # compile detected GCPs into single list
    return img_out, coverage, found_feats</code></pre>
</details>
</dd>
<dt id="satcamsim.camera.Camera.default_swath"><code class="name flex">
<span>def <span class="ident">default_swath</span></span>(<span>self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Take image composed of line scans from specified poses.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>pose_list</code></strong> :&ensp;<code>list</code> of <code><a title="satcamsim.camera.Cam_pose" href="#satcamsim.camera.Cam_pose">Cam_pose</a></code></dt>
<dd>List of poses to be used for the individual line images.</dd>
<dt><strong><code>active_sensors</code></strong> :&ensp;<code>list</code> of <code><a title="satcamsim.camera.Sensor" href="#satcamsim.camera.Sensor">Sensor</a></code>, optional</dt>
<dd>sensor objects to be used for the image. If not given, all sensors
are used.</dd>
<dt><strong><code>out_array</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>output array for in-place writing. If not given, a new array is created.</dd>
<dt><strong><code>config</code></strong> :&ensp;<code>Config</code>, optional</dt>
<dd>Dict of config parameters. If not given, default parameters are used.</dd>
<dt><strong><code>feat_finder</code></strong> :&ensp;<code>Feature_finder</code>, optional</dt>
<dd>Feature_finder instance used to detect GCPs.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>img_out</code></strong> :&ensp;<code>np.array</code></dt>
<dd>array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).</dd>
<dt><strong><code>coverage</code></strong> :&ensp;<code>shapely.geoms.Polygon</code> or <code>MultiPolygon</code></dt>
<dd>Polygon or collection of Polygons representing the ground track coverage.</dd>
<dt><strong><code>found_feats</code></strong> :&ensp;<code>list</code></dt>
<dd>list of found GCPs.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def default_swath(self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
    &#34;&#34;&#34;
    Take image composed of line scans from specified poses.

    Parameters
    ----------
    pose_list : list of Cam_pose
        List of poses to be used for the individual line images.
    active_sensors : list of Sensor, optional
        sensor objects to be used for the image. If not given, all sensors
        are used.
    out_array : np.ndarray, optional
        output array for in-place writing. If not given, a new array is created.
    config : Config, optional
        Dict of config parameters. If not given, default parameters are used.
    feat_finder : Feature_finder, optional
        Feature_finder instance used to detect GCPs.

    Returns
    -------
    img_out : np.array
        array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).
    coverage : shapely.geoms.Polygon or MultiPolygon
        Polygon or collection of Polygons representing the ground track coverage.
    found_feats : list
        list of found GCPs.

    &#34;&#34;&#34;
    with rasterio.Env() as rio_env:
        if active_sensors is None:
            active_sensors = self.sensors

        num_lines = len(pose_list)                                           # height of output image

        if out_array is None:
            num_bands = max([len(sensor.bands) for sensor in active_sensors])    # number of channels of output image
            num_pixels = max([sensor.pixels for sensor in active_sensors])       # width if output image

            # create array containing output images for all sensors and bands
            img_out = np.full((len(active_sensors), num_bands, num_lines, num_pixels), np.NaN, np.uint8)
        else:
            img_out = out_array

        coverage_geoms = list()
        found_feats = list()

        with DOP_processor.from_config(config) as dop_processor:
            for pose_idx, pose in enumerate(pose_list):
                # update pose and take new line image; write directly to output array
                _, new_coverage, new_feats = self.set_pose(pose).take_line_img(dop_processor, active_sensors, out_array=img_out[:, :, pose_idx, :], config=config, feat_finder=feat_finder)
                coverage_geoms.append(new_coverage)
                found_feats += new_feats

        coverage = unary_union(coverage_geoms)  # union of ground track coverage of individual scan lines
        return img_out, coverage, found_feats</code></pre>
</details>
</dd>
<dt id="satcamsim.camera.Camera.multiprocess_swath"><code class="name flex">
<span>def <span class="ident">multiprocess_swath</span></span>(<span>self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Take image composed of line scans from specified poses using multiprocessing.
Note that on Windows, the script running the simulation must be guarded by if <strong>name</strong> == '<strong>main</strong>'</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>pose_list</code></strong> :&ensp;<code>list</code> of <code><a title="satcamsim.camera.Cam_pose" href="#satcamsim.camera.Cam_pose">Cam_pose</a></code></dt>
<dd>List of poses to be used for the individual line images.</dd>
<dt><strong><code>active_sensors</code></strong> :&ensp;<code>list</code> of <code><a title="satcamsim.camera.Sensor" href="#satcamsim.camera.Sensor">Sensor</a></code>, optional</dt>
<dd>sensor objects to be used for the image. If not given, all sensors
are used.</dd>
<dt><strong><code>out_array</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>output array for in-place writing. If not given, a new array is created.</dd>
<dt><strong><code>config</code></strong> :&ensp;<code>Config</code>, optional</dt>
<dd>Dict of config parameters. If not given, default parameters are used.</dd>
<dt><strong><code>feat_finder</code></strong> :&ensp;<code>Feature_finder</code>, optional</dt>
<dd>Feature_finder instance used to detect GCPs.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>img_out</code></strong> :&ensp;<code>np.array</code></dt>
<dd>array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).</dd>
<dt><strong><code>coverage</code></strong> :&ensp;<code>shapely.geoms.Polygon</code> or <code>MultiPolygon</code></dt>
<dd>Polygon or collection of Polygons representing the ground track coverage.</dd>
<dt><strong><code>found_feats</code></strong> :&ensp;<code>list</code></dt>
<dd>list of found GCPs.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def multiprocess_swath(self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
    &#34;&#34;&#34;
    Take image composed of line scans from specified poses using multiprocessing.
    Note that on Windows, the script running the simulation must be guarded by if __name__ == &#39;__main__&#39;

    Parameters
    ----------
    pose_list : list of Cam_pose
        List of poses to be used for the individual line images.
    active_sensors : list of Sensor, optional
        sensor objects to be used for the image. If not given, all sensors
        are used.
    out_array : np.ndarray, optional
        output array for in-place writing. If not given, a new array is created.
    config : Config, optional
        Dict of config parameters. If not given, default parameters are used.
    feat_finder : Feature_finder, optional
        Feature_finder instance used to detect GCPs.

    Returns
    -------
    img_out : np.array
        array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).
    coverage : shapely.geoms.Polygon or MultiPolygon
        Polygon or collection of Polygons representing the ground track coverage.
    found_feats : list
        list of found GCPs.

    &#34;&#34;&#34;
    if active_sensors is None:
        active_sensors = self.sensors

    num_lines = len(pose_list)                                           # height of output image

    num_bands = max([len(sensor.bands) for sensor in active_sensors])    # number of channels of output image
    num_pixels = max([sensor.pixels for sensor in active_sensors])       # width of output image
    num_processes = config[&#39;NUM_PROCESSES&#39;]

    # split input parameters into chunks (one per process)
    split_len = int(num_lines / num_processes)
    splits = [i * split_len for i in range(num_processes)]
    splits.append(num_lines)

    split_args = [(pose_list[splits[i]:splits[i + 1]], active_sensors, None, config, feat_finder) for i in range(num_processes)]

    # pool of processes
    with mp.Pool() as pool:
        split_results = pool.starmap(self.take_swath_img_raw, split_args)

    imgs, coverage_geoms, split_feats = zip(*split_results)

    if out_array is None:
        # create array containing output images for all sensors and bands
        img_out = np.full((len(active_sensors), num_bands, num_lines, num_pixels), np.NaN, np.uint8)
    else:
        img_out = out_array

    # write to output image
    for i, img in enumerate(imgs):
        img_out[:, :, splits[i]:splits[i + 1], :] = img

    coverage = unary_union(coverage_geoms)          # union of ground track coverage from individual processes
    found_feats = chain.from_iterable(split_feats)  # compile detected GCPs into single list
    return img_out, coverage, found_feats</code></pre>
</details>
</dd>
<dt id="satcamsim.camera.Camera.multithread_swath"><code class="name flex">
<span>def <span class="ident">multithread_swath</span></span>(<span>self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Take image composed of line scans from specified poses using multithreading.
If possible, use multiprocessing instead for better performance.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>pose_list</code></strong> :&ensp;<code>list</code> of <code><a title="satcamsim.camera.Cam_pose" href="#satcamsim.camera.Cam_pose">Cam_pose</a></code></dt>
<dd>List of poses to be used for the individual line images.</dd>
<dt><strong><code>active_sensors</code></strong> :&ensp;<code>list</code> of <code><a title="satcamsim.camera.Sensor" href="#satcamsim.camera.Sensor">Sensor</a></code>, optional</dt>
<dd>sensor objects to be used for the image. If not given, all sensors
are used.</dd>
<dt><strong><code>out_array</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>output array for in-place writing. If not given, a new array is created.</dd>
<dt><strong><code>config</code></strong> :&ensp;<code>Config</code>, optional</dt>
<dd>Dict of config parameters. If not given, default parameters are used.</dd>
<dt><strong><code>feat_finder</code></strong> :&ensp;<code>Feature_finder</code>, optional</dt>
<dd>Feature_finder instance used to detect GCPs.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>img_out</code></strong> :&ensp;<code>np.array</code></dt>
<dd>array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).</dd>
<dt><strong><code>coverage</code></strong> :&ensp;<code>shapely.geoms.Polygon</code> or <code>MultiPolygon</code></dt>
<dd>Polygon or collection of Polygons representing the ground track coverage.</dd>
<dt><strong><code>found_feats</code></strong> :&ensp;<code>list</code></dt>
<dd>list of found GCPs.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def multithread_swath(self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
    &#34;&#34;&#34;
    Take image composed of line scans from specified poses using multithreading.
    If possible, use multiprocessing instead for better performance.

    Parameters
    ----------
    pose_list : list of Cam_pose
        List of poses to be used for the individual line images.
    active_sensors : list of Sensor, optional
        sensor objects to be used for the image. If not given, all sensors
        are used.
    out_array : np.ndarray, optional
        output array for in-place writing. If not given, a new array is created.
    config : Config, optional
        Dict of config parameters. If not given, default parameters are used.
    feat_finder : Feature_finder, optional
        Feature_finder instance used to detect GCPs.

    Returns
    -------
    img_out : np.array
        array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).
    coverage : shapely.geoms.Polygon or MultiPolygon
        Polygon or collection of Polygons representing the ground track coverage.
    found_feats : list
        list of found GCPs.

    &#34;&#34;&#34;
    if active_sensors is None:
        active_sensors = self.sensors

    num_threads = config[&#39;NUM_THREADS&#39;]
    num_lines = len(pose_list)                                           # height of output image

    if out_array is None:
        num_bands = max([len(sensor.bands) for sensor in active_sensors])    # number of channels of output image
        num_pixels = max([sensor.pixels for sensor in active_sensors])       # width if output image

        # create array containing output images for all sensors and bands
        img_out = np.full((len(active_sensors), num_bands, num_lines, num_pixels), np.NaN, np.uint8)
    else:
        img_out = out_array

    # split input parameters into chunks (one per process)
    split_len = int(num_lines / num_threads)
    splits = [i * split_len for i in range(num_threads)]
    splits.append(num_lines)

    split_args = [(pose_list[splits[i]:splits[i + 1]], active_sensors, img_out[:, :, splits[i]:splits[i + 1], :], config, feat_finder)
                  for i in range(num_threads)]

    # pool of threads
    with ThreadPoolExecutor(max_workers=num_threads) as executor:
        split_results = executor.map(lambda args: self.take_swath_img_raw(*args), split_args)

    _, coverage_geoms, split_feats = zip(*split_results)
    coverage = unary_union(coverage_geoms)          # union of ground track coverage from individual threads
    found_feats = chain.from_iterable(split_feats)  # compile detected GCPs into single list
    return img_out, coverage, found_feats</code></pre>
</details>
</dd>
<dt id="satcamsim.camera.Camera.postprocess"><code class="name flex">
<span>def <span class="ident">postprocess</span></span>(<span>img_raw, PSF=None, SNR=None, config=get_config())</span>
</code></dt>
<dd>
<div class="desc"><p>Artificially degrade (filter and noisify) simulated image.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>img_raw</code></strong> :&ensp;<code>np.array</code></dt>
<dd>array of simulated images without added filter/noise, shape (n_sensors, n_bands, n_lines, n_pixels).</dd>
<dt><strong><code>PSF</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>Filter mask representing the point spread function, sampled at the pixel grid nodes. If not given, no filter is applied.
If PSF.ndim == 2, all bands of all sensors are degraded with the same PSF.
If PSF.ndim == 3, all bands of each sensor are degraded with the same PSF, and must have PSF.shape[0] == n_bands.
If PSF.ndim == 4, every band of every sensor is degraded with an individual PSF, and must have PSF.shape[0] == sensors, PSF.shape[1] == n_bands.</dd>
<dt><strong><code>SNR</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>Signal-to-noise ratios for addition of AWGN. Same conventions for shape as PSF. If not given, no noise is added.</dd>
<dt><strong><code>config</code></strong> :&ensp;<code>Config</code>, optional</dt>
<dd>Config dict containing parameters for the simulation run. If not given, default parameters are used.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>img_out</code></strong> :&ensp;<code>np.array</code></dt>
<dd>array of simulated images after degradation, shape (n_sensors, n_bands, n_lines, n_pixels).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def postprocess(img_raw, PSF=None, SNR=None, config=get_config()):
    &#34;&#34;&#34;
    Artificially degrade (filter and noisify) simulated image.

    Parameters
    ----------
    img_raw : np.array
        array of simulated images without added filter/noise, shape (n_sensors, n_bands, n_lines, n_pixels).
    PSF : np.ndarray, optional
        Filter mask representing the point spread function, sampled at the pixel grid nodes. If not given, no filter is applied.
        If PSF.ndim == 2, all bands of all sensors are degraded with the same PSF.
        If PSF.ndim == 3, all bands of each sensor are degraded with the same PSF, and must have PSF.shape[0] == n_bands.
        If PSF.ndim == 4, every band of every sensor is degraded with an individual PSF, and must have PSF.shape[0] == sensors, PSF.shape[1] == n_bands.
    SNR : np.ndarray, optional
        Signal-to-noise ratios for addition of AWGN. Same conventions for shape as PSF. If not given, no noise is added.
    config : Config, optional
        Config dict containing parameters for the simulation run. If not given, default parameters are used.

    Returns
    -------
    img_out : np.array
        array of simulated images after degradation, shape (n_sensors, n_bands, n_lines, n_pixels).

    &#34;&#34;&#34;
    img_out = img_raw.copy()

    # apply PSF
    if PSF is not None:
        while PSF.ndim &lt; img_out.ndim:
            PSF = PSF[None, :]

        if PSF.shape[0] != img_out.shape[0]:
            PSF = np.repeat(PSF, img_out.shape[0], axis=0)

        if PSF.shape[1] != img_out.shape[1]:
            PSF = np.repeat(PSF, img_out.shape[1], axis=1)

        for sensor_idx in range(img_out.shape[0]):
            for band_idx in range(img_out.shape[1]):
                img_out[sensor_idx, band_idx, :, :] = convolve2d(img_out[sensor_idx, band_idx, :, :], PSF[sensor_idx, band_idx, :, :], mode=&#39;same&#39;, boundary=&#39;symm&#39;)

    # noise
    if config[&#39;NOISY&#39;] and (SNR is not None):
        while SNR.ndim &lt; img_out.ndim - 2:
            SNR = SNR[None, :]

        if SNR.shape[0] != img_out.shape[0]:
            SNR = np.repeat(SNR, img_out.shape[0], axis=0)

        if SNR.shape[1] != img_out.shape[1]:
            SNR = np.repeat(SNR, img_out.shape[1], axis=1)

        noise = np.empty(img_out.shape, dtype=float)

        for sensor_idx in range(img_out.shape[0]):
            for band_idx in range(img_out.shape[1]):
                sigma = np.mean(img_raw[sensor_idx, band_idx, :, :][np.where(img_raw[sensor_idx, band_idx, :, :])]) / SNR[sensor_idx, band_idx]
                noise[sensor_idx, band_idx, :, :] = np.random.normal(0, sigma, img_raw[sensor_idx, band_idx, :, :].shape)   # independent noise for each band

        img_out = np.clip((img_out.astype(float) + noise), 0, 255).astype(np.uint8)

    # preserve nodata entries
    img_out = np.where(img_raw, img_out, 0)
    return img_out</code></pre>
</details>
</dd>
<dt id="satcamsim.camera.Camera.set_pose"><code class="name flex">
<span>def <span class="ident">set_pose</span></span>(<span>self, pose)</span>
</code></dt>
<dd>
<div class="desc"><p>Specify exterior orientation of camera.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>pose</code></strong> :&ensp;<code><a title="satcamsim.camera.Cam_pose" href="#satcamsim.camera.Cam_pose">Cam_pose</a></code></dt>
<dd>pose of the camera</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>self</code></strong> :&ensp;<code><a title="satcamsim.camera.Camera" href="#satcamsim.camera.Camera">Camera</a></code></dt>
<dd>updated camera instance.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_pose(self, pose):
    &#34;&#34;&#34;
    Specify exterior orientation of camera.

    Parameters
    ----------
    pose : Cam_pose
        pose of the camera

    Returns
    -------
    self : Camera
        updated camera instance.
    &#34;&#34;&#34;
    self.pose = pose
    for sensor in self.sensors:
        sensor.pose = self.pose
    return self</code></pre>
</details>
</dd>
<dt id="satcamsim.camera.Camera.simulate_swath"><code class="name flex">
<span>def <span class="ident">simulate_swath</span></span>(<span>self, pose_list, active_sensors=None, out_array=None, PSF=None, config=get_config())</span>
</code></dt>
<dd>
<div class="desc"><p>Simulate image composed of line scans from specified poses, and artificially degrade it as specified by PSF and Sensor.SNR.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>pose_list</code></strong> :&ensp;<code>list</code> of <code><a title="satcamsim.camera.Cam_pose" href="#satcamsim.camera.Cam_pose">Cam_pose</a></code></dt>
<dd>List of poses to be used for the individual line images.</dd>
<dt><strong><code>active_sensors</code></strong> :&ensp;<code>list</code> of <code><a title="satcamsim.camera.Sensor" href="#satcamsim.camera.Sensor">Sensor</a></code>, optional</dt>
<dd>sensor objects to be used for the image. If not given, all sensors
are used.</dd>
<dt><strong><code>out_array</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>output array for in-place writing. If not given, a new array is created.</dd>
<dt><strong><code>PSF</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>Filter mask representing the point spread function, sampled at the pixel grid nodes. If not given, no filter is applied.
If PSF.ndim == 2, all bands of all sensors are degraded with the same PSF.
If PSF.ndim == 3, all bands of each sensor are degraded with the same PSF, and must have PSF.shape[0] == n_bands.
If PSF.ndim == 4, every band of every sensor is degraded with an individual PSF, and must have PSF.shape[0] == sensors, PSF.shape[1] == n_bands.</dd>
<dt><strong><code>config</code></strong> :&ensp;<code>Config</code>, optional</dt>
<dd>Config dict containing parameters for the simulation run. If not provided, default parameters are used.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>img_out</code></strong> :&ensp;<code>np.array</code></dt>
<dd>array of simulated images after degradation according to config, shape (n_sensors, n_bands, n_lines, n_pixels).</dd>
<dt><strong><code>coverage</code></strong> :&ensp;<code>shapely.geoms.Polygon</code> or <code>MultiPolygon</code></dt>
<dd>Polygon or collection of Polygons representing the ground track coverage.</dd>
<dt><strong><code>found_feats</code></strong> :&ensp;<code>list</code></dt>
<dd>list of found GCPs.</dd>
<dt><strong><code>img_raw</code></strong> :&ensp;<code>np.array</code></dt>
<dd>array of simulated images without added filter/noise, shape (n_sensors, n_bands, n_lines, n_pixels).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def simulate_swath(self, pose_list, active_sensors=None, out_array=None, PSF=None, config=get_config()):
    &#34;&#34;&#34;
    Simulate image composed of line scans from specified poses, and artificially degrade it as specified by PSF and Sensor.SNR.

    Parameters
    ----------
    pose_list : list of Cam_pose
        List of poses to be used for the individual line images.
    active_sensors : list of Sensor, optional
        sensor objects to be used for the image. If not given, all sensors
        are used.
    out_array : np.ndarray, optional
        output array for in-place writing. If not given, a new array is created.
    PSF : np.ndarray, optional
        Filter mask representing the point spread function, sampled at the pixel grid nodes. If not given, no filter is applied.
        If PSF.ndim == 2, all bands of all sensors are degraded with the same PSF.
        If PSF.ndim == 3, all bands of each sensor are degraded with the same PSF, and must have PSF.shape[0] == n_bands.
        If PSF.ndim == 4, every band of every sensor is degraded with an individual PSF, and must have PSF.shape[0] == sensors, PSF.shape[1] == n_bands.
    config : Config, optional
        Config dict containing parameters for the simulation run. If not provided, default parameters are used.

    Returns
    -------
    img_out : np.array
        array of simulated images after degradation according to config, shape (n_sensors, n_bands, n_lines, n_pixels).
    coverage : shapely.geoms.Polygon or MultiPolygon
        Polygon or collection of Polygons representing the ground track coverage.
    found_feats : list
        list of found GCPs.
    img_raw : np.array
        array of simulated images without added filter/noise, shape (n_sensors, n_bands, n_lines, n_pixels).

    &#34;&#34;&#34;
    if config[&#39;FIND_FEATURES&#39;]:
        feat_finder = Feature_finder.from_config(config)
    else:
        feat_finder = None

    img_raw, coverage, found_feats = self.take_swath_img_raw(pose_list, active_sensors, out_array, config, feat_finder)

    if config[&#39;NOISY&#39;] or (PSF is not None):
        SNR = np.array([sensor.SNRs for sensor in self.sensors])
        img_out = Camera.postprocess(img_raw, PSF, SNR, config)
    else:
        img_out = img_raw

    return img_out, coverage, found_feats, img_raw</code></pre>
</details>
</dd>
<dt id="satcamsim.camera.Camera.take_line_img"><code class="name flex">
<span>def <span class="ident">take_line_img</span></span>(<span>self, dop_processor, active_sensors=None, out_array=None, config=get_config(), feat_finder=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Acquire a single line image from the current pose using the specified sensors.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dop_processor</code></strong> :&ensp;<code>DOP_processor</code></dt>
<dd>DOP_processor instance used to read data from DOP.</dd>
<dt><strong><code>active_sensors</code></strong> :&ensp;<code>list</code> of <code><a title="satcamsim.camera.Sensor" href="#satcamsim.camera.Sensor">Sensor</a></code>, optional</dt>
<dd>Sensor objects to be used for the image. If not given, all sensors
are used.</dd>
<dt><strong><code>out_array</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>output array for in-place writing. If not given, a new array is created.</dd>
<dt><strong><code>config</code></strong> :&ensp;<code>Config</code>, optional</dt>
<dd>Dict of config parameters. If not given, default parameters are used.</dd>
<dt><strong><code>feat_finder</code></strong> :&ensp;<code>Feature_finder</code>, optional</dt>
<dd>Feature_finder instance used to detect GCPs.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>img_out</code></strong> :&ensp;<code>np.ndarray</code> of <code>np.uint8</code></dt>
<dd>array of simulated images, shape (n_sensors, n_bands, 1, n_pixels).</dd>
<dt><strong><code>coverage</code></strong> :&ensp;<code>Polygon</code> or <code>MultiPolygon</code></dt>
<dd>Polygon or collection of Polygons representing the ground track coverage.</dd>
<dt><strong><code>found_feats</code></strong> :&ensp;<code>list</code></dt>
<dd>list of found GCPs.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def take_line_img(self, dop_processor, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
    &#34;&#34;&#34;
    Acquire a single line image from the current pose using the specified sensors.

    Parameters
    ----------
    dop_processor : DOP_processor
        DOP_processor instance used to read data from DOP.
    active_sensors : list of Sensor, optional
        Sensor objects to be used for the image. If not given, all sensors
        are used.
    out_array : np.ndarray, optional
        output array for in-place writing. If not given, a new array is created.
    config : Config, optional
        Dict of config parameters. If not given, default parameters are used.
    feat_finder : Feature_finder, optional
        Feature_finder instance used to detect GCPs.

    Returns
    -------
    img_out : np.ndarray of np.uint8
        array of simulated images, shape (n_sensors, n_bands, 1, n_pixels).
    coverage : Polygon or MultiPolygon
        Polygon or collection of Polygons representing the ground track coverage.
    found_feats : list
        list of found GCPs.

    &#34;&#34;&#34;
    if active_sensors is None:
        active_sensors = self.sensors

    if out_array is None:
        num_bands = max([len(sensor.bands) for sensor in active_sensors])
        num_pixels = max([sensor.pixels for sensor in active_sensors])
        img_out = np.full((len(active_sensors), num_bands, num_pixels), np.NaN, np.uint8)
    else:
        img_out = out_array

    coverage_geoms = list()
    found_feats = list()

    for sensor_idx, sensor in enumerate(active_sensors):
        # take line images with all specified sensors
        img_out[sensor_idx, :, :], new_coverage, new_feats = sensor.take_line_img(dop_processor, config, feat_finder)

        # add ground covered in new line image
        coverage_geoms.append(new_coverage)
        found_feats += new_feats

    coverage = unary_union(coverage_geoms)  # union of ground track coverage of individual pixels
    return img_out, coverage, found_feats</code></pre>
</details>
</dd>
<dt id="satcamsim.camera.Camera.take_swath_img_raw"><code class="name flex">
<span>def <span class="ident">take_swath_img_raw</span></span>(<span>self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Take image composed of line scans from specified poses, without any degradation effects.
Maps arguments to the corresponding Sim_mode.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt>pose_list : list of Cam_pose</dt>
<dt>List of poses to be used for the individual line images.</dt>
<dt>active_sensors : list of Sensor, optional</dt>
<dt>sensor objects to be used for the image. If not given, all sensors</dt>
<dt>are used.</dt>
<dt>out_array : np.ndarray, optional</dt>
<dt>output array for in-place writing. If not given, a new array is created.</dt>
<dt><strong><code>config</code></strong> :&ensp;<code>Config</code>, optional</dt>
<dd>Config dict containing parameters for the simulation run. If not provided, default parameters are used.</dd>
<dt><strong><code>feat_finder</code></strong> :&ensp;<code>Feature_finder</code>, optional</dt>
<dd>Feature_finder instance used to detect GCPs.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>img_out</code></strong> :&ensp;<code>np.array</code></dt>
<dd>array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).</dd>
<dt><strong><code>coverage</code></strong> :&ensp;<code>shapely.geoms.Polygon</code> or <code>MultiPolygon</code></dt>
<dd>Polygon or collection of Polygons representing the ground track coverage.</dd>
<dt><strong><code>found_feats</code></strong> :&ensp;<code>list</code></dt>
<dd>list of found GCPs.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def take_swath_img_raw(self, pose_list, active_sensors=None, out_array=None, config=get_config(), feat_finder=None):
    &#34;&#34;&#34;
    Take image composed of line scans from specified poses, without any degradation effects.
    Maps arguments to the corresponding Sim_mode.

    Parameters
    ----------
     pose_list : list of Cam_pose
         List of poses to be used for the individual line images.
     active_sensors : list of Sensor, optional
         sensor objects to be used for the image. If not given, all sensors
         are used.
     out_array : np.ndarray, optional
         output array for in-place writing. If not given, a new array is created.
    config : Config, optional
         Config dict containing parameters for the simulation run. If not provided, default parameters are used.
    feat_finder : Feature_finder, optional
        Feature_finder instance used to detect GCPs.

    Returns
    -------
    img_out : np.array
        array of simulated images, shape (n_sensors, n_bands, n_lines, n_pixels).
    coverage : shapely.geoms.Polygon or MultiPolygon
        Polygon or collection of Polygons representing the ground track coverage.
    found_feats : list
        list of found GCPs.

    &#34;&#34;&#34;
    config = config.copy()
    sim_modes = config[&#39;SIM_MODES&#39;]
    sim_mode = sim_modes[0]
    config[&#39;SIM_MODES&#39;] = sim_modes[1:]

    if sim_mode == Sim_modes.DEFAULT:
        if sim_modes[1:]:
            raise ValueError(&#39;sim_modes must not specify additional simulation modes following a Sim_modes.DEFAULT entry&#39;)
        return self.default_swath(pose_list, active_sensors, out_array, config, feat_finder)

    elif sim_mode == Sim_modes.PROCESSES:
        return self.multiprocess_swath(pose_list, active_sensors, out_array, config, feat_finder)

    elif sim_mode == Sim_modes.THREADS:
        return self.multithread_swath(pose_list, active_sensors, out_array, config, feat_finder)

    elif sim_mode == Sim_modes.CHUNKS:
        return self.chunky_swath(pose_list, active_sensors, out_array, config, feat_finder)

    else:
        raise ValueError(&#39;sim_modes must only contain members of camera.Sim_modes&#39;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="satcamsim.camera.Interior_orientation"><code class="flex name class">
<span>class <span class="ident">Interior_orientation</span></span>
<span>(</span><span>x0, y0, c)</span>
</code></dt>
<dd>
<div class="desc"><p>Interior_orientation object to specify location of image principal point.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x0</code></strong> :&ensp;<code>float</code></dt>
<dd>principal point x offset in mm</dd>
<dt><strong><code>y0</code></strong> :&ensp;<code>float</code></dt>
<dd>principal point y offset in mm</dd>
<dt><strong><code>c</code></strong> :&ensp;<code>float</code></dt>
<dd>camera focal length in mm</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>interior</code></strong> :&ensp;<code><a title="satcamsim.camera.Interior_orientation" href="#satcamsim.camera.Interior_orientation">Interior_orientation</a></code></dt>
<dd>a new Interior_orientation instance.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Interior_orientation:
    &#34;&#34;&#34;
    Interior_orientation object to specify location of image principal point.

    Parameters
    ----------
    x0 : float
        principal point x offset in mm
    y0 : float
        principal point y offset in mm
    c : float
        camera focal length in mm

    Returns
    -------
    interior : Interior_orientation
        a new Interior_orientation instance.

    &#34;&#34;&#34;

    def __init__(self, x0, y0, c):
        self.x0 = x0
        self.y0 = y0
        self.c = c
        return</code></pre>
</details>
</dd>
<dt id="satcamsim.camera.Sensor"><code class="flex name class">
<span>class <span class="ident">Sensor</span></span>
<span>(</span><span>name_str, bands, interior_orientation, pixels, px_size, SNRs)</span>
</code></dt>
<dd>
<div class="desc"><p>Sensor object with own geometry and recorded bands.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>name_str</code></strong> :&ensp;<code>string</code></dt>
<dd>used as sensor name</dd>
<dt><strong><code>bands</code></strong> :&ensp;<code>tuple</code> of <code>int</code></dt>
<dd>indices of recorded bands from input image file</dd>
<dt><strong><code>interior_orientation</code></strong> :&ensp;<code><a title="satcamsim.camera.Interior_orientation" href="#satcamsim.camera.Interior_orientation">Interior_orientation</a></code></dt>
<dd>interior parameters of the camera</dd>
<dt><strong><code>pixels</code></strong> :&ensp;<code>int</code></dt>
<dd>number of pixels in the line sensor</dd>
<dt><strong><code>px_size</code></strong> :&ensp;<code>float</code></dt>
<dd>size of one pixel on the sensor</dd>
<dt><strong><code>SNRs</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>array containing signal-to-noise ratio of each band. Must have same length as bands</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>sensor</code></strong> :&ensp;<code><a title="satcamsim.camera.Sensor" href="#satcamsim.camera.Sensor">Sensor</a></code></dt>
<dd>a new Sensor instance</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Sensor:
    &#34;&#34;&#34;
    Sensor object with own geometry and recorded bands.

    Parameters
    ----------
    name_str : string
        used as sensor name
    bands : tuple of int
        indices of recorded bands from input image file
    interior_orientation : Interior_orientation
        interior parameters of the camera
    pixels : int
        number of pixels in the line sensor
    px_size : float
        size of one pixel on the sensor
    SNRs : np.ndarray
        array containing signal-to-noise ratio of each band. Must have same length as bands

    Returns
    -------
    sensor : Sensor
        a new Sensor instance

    &#34;&#34;&#34;

    def __init__(self, name_str, bands, interior_orientation, pixels, px_size, SNRs):
        self.name = name_str
        self.bands = bands
        self.SNRs = np.array(SNRs)
        if self.SNRs.size != len(self.bands) and self.SNRs.size != 1:
            raise ValueError(&#39;Specify one SNR per band, or one SNR to be used for all bands&#39;)
        self.interior_orientation = interior_orientation
        self.pixels = pixels
        self.px_size = px_size
        self.pose = None
        self.prev_pose = None
        self.prev_corners_XY = None
        self.px_corners_xy = self.get_px_corners()
        return

    def get_px_corners(self):
        &#34;&#34;&#34;
        Compute location of pixel corners in image coordinates.

        Returns
        -------
        corners_xy : np.ndarray of float
            coordinates of all pixel corners, shape (2, self.pixels + 1, 1).
            corners_xy[0, :, :] contains x values, corners_xy[1, :, :] y values.
            Corners are sorted according to ascending x.

        &#34;&#34;&#34;
        # horizontal positions of pixel corners in pixel coordinates
        px_cs = np.linspace(-.5, self.pixels + .5, self.pixels + 1)

        # vertical position of pixel corners in pixel coordinates (zero by definition)
        px_rs = np.zeros(px_cs.shape)

        # merge r and c values
        corners_rc = np.stack([px_rs, px_cs], axis=0)

        corners_xy = self.pixels_to_imgcoord(corners_rc)
        return corners_xy

    def pixels_to_imgcoord(self, coords_rc):
        &#34;&#34;&#34;
        Compute image coordinates of a location in output image pixel coordinate system.

        Parameters
        ----------
        coords_rc : np.ndarray of float
            array of shape (2, ...), where coords_rc[0] contains only r coordinates, coords_rc[1] contains corresponding c coordinates.

        Returns
        -------
        coords_xy : np.ndarray of float
            array of shape coords_rc.shape, where coords_xy[0] contains only x coordinates, coords_xy[1] contains corresponding y coordinates.

        &#34;&#34;&#34;
        # r = coords_rc[0]
        # c = coords_rc[1]

        x = (coords_rc[1] + 0.5) * self.px_size - self.px_size * self.pixels / 2
        y = - coords_rc[0] * self.px_size
        return np.array([x, y])

    def get_object_coordinates(self, img_coord, Z_terrain=0, pose=None):
        &#34;&#34;&#34;
        Compute projection of image coordinates onto terrain in current pose.

        Parameters
        ----------
        img_coord : np.ndarray of float
            array of shape (2, ...), where img_coord[0] contains only x coordinates, img_coord[1] contains corresponding y coordinates.
        Z_terrain : float, optional
            vertical height of terrain at position (X,Y). The default is 0.
        pose : Cam_pose, optional
            pose representing exterior orientation to be used for calculation. If not given, current self.pose of the sensor is used.

        Returns
        -------
        coords_XY: np.ndarray of float
            array of shape img_coord.shape, where coords_XY[0] contains only X coordinates, coords_XY[1] contains corresponding Y coordinates.

        &#34;&#34;&#34;
        if pose is None:
            pose = self.pose

        delta_x = self.interior_orientation.x0 - img_coord[0]
        delta_y = self.interior_orientation.y0 - img_coord[1]

        denominator = pose.R[2, 0] * delta_x + pose.R[2, 1] * delta_y + pose.R[2, 2] * self.interior_orientation.c
        const_factor = (Z_terrain - pose.XYZ_0[2]) / denominator

        X = pose.XYZ_0[0] + const_factor * \
            (pose.R[0, 0] * delta_x + pose.R[0, 1] * delta_y - pose.R[0, 2] * self.interior_orientation.c)
        Y = pose.XYZ_0[1] + const_factor * \
            (pose.R[1, 0] * delta_x + pose.R[1, 1] * delta_y - pose.R[1, 2] * self.interior_orientation.c)
        return np.stack([X, Y])

    def take_line_img(self, dop_processor, config=get_config(), feat_finder=None):
        &#34;&#34;&#34;
        Acquire a single line image from current camera pose.

        Parameters
        ----------
        dop_processor : DOP_processor
            DOP_processor instance used to read data from DOP.
        config : Config, optional
            Dict of config parameters. If not given, default parameters are used.
        feat_finder : Feature_finder, optional
            Feature_finder instance used to detect GCPs.

        Returns
        -------
        img_out : np.array
            output images for all bands in self.bands, has shape (len(self.bands), 1, self.pixels).
        coverage : shapely.geoms.Polygon or MultiPolygon
            Polygon or collection of Polygons representing the ground track coverage.
         found_feats : list
             list of found GCPs.

        &#34;&#34;&#34;
        img_out = np.zeros((len(self.bands), self.pixels), np.uint8)
        coverage_list = list()
        found_feats = list()

        new_corners_XY = self.get_object_coordinates(self.px_corners_xy, Z_terrain=config[&#39;MEAN_TERRAIN_HEIGHT&#39;])
        if (not self.prev_pose == self.pose.previous) or (self.prev_corners_XY is None):
            if not self.pose.previous:
                return img_out, Polygon(), []
            self.prev_corners_XY = self.get_object_coordinates(self.px_corners_xy, Z_terrain=config[&#39;MEAN_TERRAIN_HEIGHT&#39;], pose=self.pose.previous)

        for pixel in range(self.pixels):
            # pixel corners in object (XY) coordinates
            pixel_corners_XY = [tuple(new_corners_XY[:, pixel]),
                                tuple(self.prev_corners_XY[:, pixel]),
                                tuple(self.prev_corners_XY[:, pixel + 1]),
                                tuple(new_corners_XY[:, pixel + 1])]

            is_success, sample, new_coverage = dop_processor.sample_area(pixel_corners_XY, self.bands)

            if feat_finder:
                found_feats += feat_finder.check(new_coverage, pixel_corners_XY, self.pose.idx, pixel, self.name, self.pose)

            # update ground track coverage with new pixel area
            coverage_list.append(new_coverage)

            if not is_success:
                img_out[:, pixel] = 0   # write 0 (no data) to output image
                continue

            # take mean value of all contained DOP raster points (for each band) and write to output image
            img_out[:, pixel] = sample

        self.prev_pose = self.pose              # update previous pose
        self.prev_corners_XY = new_corners_XY   # update projected corner coordinates
        coverage = unary_union(coverage_list)
        return img_out, coverage, found_feats</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="satcamsim.camera.Sensor.get_object_coordinates"><code class="name flex">
<span>def <span class="ident">get_object_coordinates</span></span>(<span>self, img_coord, Z_terrain=0, pose=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute projection of image coordinates onto terrain in current pose.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>img_coord</code></strong> :&ensp;<code>np.ndarray</code> of <code>float</code></dt>
<dd>array of shape (2, &hellip;), where img_coord[0] contains only x coordinates, img_coord[1] contains corresponding y coordinates.</dd>
<dt><strong><code>Z_terrain</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>vertical height of terrain at position (X,Y). The default is 0.</dd>
<dt><strong><code>pose</code></strong> :&ensp;<code><a title="satcamsim.camera.Cam_pose" href="#satcamsim.camera.Cam_pose">Cam_pose</a></code>, optional</dt>
<dd>pose representing exterior orientation to be used for calculation. If not given, current self.pose of the sensor is used.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>coords_XY</code></strong> :&ensp;<code>np.ndarray</code> of <code>float</code></dt>
<dd>array of shape img_coord.shape, where coords_XY[0] contains only X coordinates, coords_XY[1] contains corresponding Y coordinates.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_object_coordinates(self, img_coord, Z_terrain=0, pose=None):
    &#34;&#34;&#34;
    Compute projection of image coordinates onto terrain in current pose.

    Parameters
    ----------
    img_coord : np.ndarray of float
        array of shape (2, ...), where img_coord[0] contains only x coordinates, img_coord[1] contains corresponding y coordinates.
    Z_terrain : float, optional
        vertical height of terrain at position (X,Y). The default is 0.
    pose : Cam_pose, optional
        pose representing exterior orientation to be used for calculation. If not given, current self.pose of the sensor is used.

    Returns
    -------
    coords_XY: np.ndarray of float
        array of shape img_coord.shape, where coords_XY[0] contains only X coordinates, coords_XY[1] contains corresponding Y coordinates.

    &#34;&#34;&#34;
    if pose is None:
        pose = self.pose

    delta_x = self.interior_orientation.x0 - img_coord[0]
    delta_y = self.interior_orientation.y0 - img_coord[1]

    denominator = pose.R[2, 0] * delta_x + pose.R[2, 1] * delta_y + pose.R[2, 2] * self.interior_orientation.c
    const_factor = (Z_terrain - pose.XYZ_0[2]) / denominator

    X = pose.XYZ_0[0] + const_factor * \
        (pose.R[0, 0] * delta_x + pose.R[0, 1] * delta_y - pose.R[0, 2] * self.interior_orientation.c)
    Y = pose.XYZ_0[1] + const_factor * \
        (pose.R[1, 0] * delta_x + pose.R[1, 1] * delta_y - pose.R[1, 2] * self.interior_orientation.c)
    return np.stack([X, Y])</code></pre>
</details>
</dd>
<dt id="satcamsim.camera.Sensor.get_px_corners"><code class="name flex">
<span>def <span class="ident">get_px_corners</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute location of pixel corners in image coordinates.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>corners_xy</code></strong> :&ensp;<code>np.ndarray</code> of <code>float</code></dt>
<dd>coordinates of all pixel corners, shape (2, self.pixels + 1, 1).
corners_xy[0, :, :] contains x values, corners_xy[1, :, :] y values.
Corners are sorted according to ascending x.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_px_corners(self):
    &#34;&#34;&#34;
    Compute location of pixel corners in image coordinates.

    Returns
    -------
    corners_xy : np.ndarray of float
        coordinates of all pixel corners, shape (2, self.pixels + 1, 1).
        corners_xy[0, :, :] contains x values, corners_xy[1, :, :] y values.
        Corners are sorted according to ascending x.

    &#34;&#34;&#34;
    # horizontal positions of pixel corners in pixel coordinates
    px_cs = np.linspace(-.5, self.pixels + .5, self.pixels + 1)

    # vertical position of pixel corners in pixel coordinates (zero by definition)
    px_rs = np.zeros(px_cs.shape)

    # merge r and c values
    corners_rc = np.stack([px_rs, px_cs], axis=0)

    corners_xy = self.pixels_to_imgcoord(corners_rc)
    return corners_xy</code></pre>
</details>
</dd>
<dt id="satcamsim.camera.Sensor.pixels_to_imgcoord"><code class="name flex">
<span>def <span class="ident">pixels_to_imgcoord</span></span>(<span>self, coords_rc)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute image coordinates of a location in output image pixel coordinate system.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>coords_rc</code></strong> :&ensp;<code>np.ndarray</code> of <code>float</code></dt>
<dd>array of shape (2, &hellip;), where coords_rc[0] contains only r coordinates, coords_rc[1] contains corresponding c coordinates.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>coords_xy</code></strong> :&ensp;<code>np.ndarray</code> of <code>float</code></dt>
<dd>array of shape coords_rc.shape, where coords_xy[0] contains only x coordinates, coords_xy[1] contains corresponding y coordinates.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pixels_to_imgcoord(self, coords_rc):
    &#34;&#34;&#34;
    Compute image coordinates of a location in output image pixel coordinate system.

    Parameters
    ----------
    coords_rc : np.ndarray of float
        array of shape (2, ...), where coords_rc[0] contains only r coordinates, coords_rc[1] contains corresponding c coordinates.

    Returns
    -------
    coords_xy : np.ndarray of float
        array of shape coords_rc.shape, where coords_xy[0] contains only x coordinates, coords_xy[1] contains corresponding y coordinates.

    &#34;&#34;&#34;
    # r = coords_rc[0]
    # c = coords_rc[1]

    x = (coords_rc[1] + 0.5) * self.px_size - self.px_size * self.pixels / 2
    y = - coords_rc[0] * self.px_size
    return np.array([x, y])</code></pre>
</details>
</dd>
<dt id="satcamsim.camera.Sensor.take_line_img"><code class="name flex">
<span>def <span class="ident">take_line_img</span></span>(<span>self, dop_processor, config=get_config(), feat_finder=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Acquire a single line image from current camera pose.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dop_processor</code></strong> :&ensp;<code>DOP_processor</code></dt>
<dd>DOP_processor instance used to read data from DOP.</dd>
<dt><strong><code>config</code></strong> :&ensp;<code>Config</code>, optional</dt>
<dd>Dict of config parameters. If not given, default parameters are used.</dd>
<dt><strong><code>feat_finder</code></strong> :&ensp;<code>Feature_finder</code>, optional</dt>
<dd>Feature_finder instance used to detect GCPs.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>img_out</code></strong> :&ensp;<code>np.array</code></dt>
<dd>output images for all bands in self.bands, has shape (len(self.bands), 1, self.pixels).</dd>
<dt><strong><code>coverage</code></strong> :&ensp;<code>shapely.geoms.Polygon</code> or <code>MultiPolygon</code></dt>
<dd>Polygon or collection of Polygons representing the ground track coverage.</dd>
</dl>
<p>found_feats : list
list of found GCPs.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def take_line_img(self, dop_processor, config=get_config(), feat_finder=None):
    &#34;&#34;&#34;
    Acquire a single line image from current camera pose.

    Parameters
    ----------
    dop_processor : DOP_processor
        DOP_processor instance used to read data from DOP.
    config : Config, optional
        Dict of config parameters. If not given, default parameters are used.
    feat_finder : Feature_finder, optional
        Feature_finder instance used to detect GCPs.

    Returns
    -------
    img_out : np.array
        output images for all bands in self.bands, has shape (len(self.bands), 1, self.pixels).
    coverage : shapely.geoms.Polygon or MultiPolygon
        Polygon or collection of Polygons representing the ground track coverage.
     found_feats : list
         list of found GCPs.

    &#34;&#34;&#34;
    img_out = np.zeros((len(self.bands), self.pixels), np.uint8)
    coverage_list = list()
    found_feats = list()

    new_corners_XY = self.get_object_coordinates(self.px_corners_xy, Z_terrain=config[&#39;MEAN_TERRAIN_HEIGHT&#39;])
    if (not self.prev_pose == self.pose.previous) or (self.prev_corners_XY is None):
        if not self.pose.previous:
            return img_out, Polygon(), []
        self.prev_corners_XY = self.get_object_coordinates(self.px_corners_xy, Z_terrain=config[&#39;MEAN_TERRAIN_HEIGHT&#39;], pose=self.pose.previous)

    for pixel in range(self.pixels):
        # pixel corners in object (XY) coordinates
        pixel_corners_XY = [tuple(new_corners_XY[:, pixel]),
                            tuple(self.prev_corners_XY[:, pixel]),
                            tuple(self.prev_corners_XY[:, pixel + 1]),
                            tuple(new_corners_XY[:, pixel + 1])]

        is_success, sample, new_coverage = dop_processor.sample_area(pixel_corners_XY, self.bands)

        if feat_finder:
            found_feats += feat_finder.check(new_coverage, pixel_corners_XY, self.pose.idx, pixel, self.name, self.pose)

        # update ground track coverage with new pixel area
        coverage_list.append(new_coverage)

        if not is_success:
            img_out[:, pixel] = 0   # write 0 (no data) to output image
            continue

        # take mean value of all contained DOP raster points (for each band) and write to output image
        img_out[:, pixel] = sample

    self.prev_pose = self.pose              # update previous pose
    self.prev_corners_XY = new_corners_XY   # update projected corner coordinates
    coverage = unary_union(coverage_list)
    return img_out, coverage, found_feats</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="satcamsim" href="index.html">satcamsim</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="satcamsim.camera.Cam_pose" href="#satcamsim.camera.Cam_pose">Cam_pose</a></code></h4>
<ul class="two-column">
<li><code><a title="satcamsim.camera.Cam_pose.R_img2sat" href="#satcamsim.camera.Cam_pose.R_img2sat">R_img2sat</a></code></li>
<li><code><a title="satcamsim.camera.Cam_pose.copy" href="#satcamsim.camera.Cam_pose.copy">copy</a></code></li>
<li><code><a title="satcamsim.camera.Cam_pose.crs_obj" href="#satcamsim.camera.Cam_pose.crs_obj">crs_obj</a></code></li>
<li><code><a title="satcamsim.camera.Cam_pose.lla" href="#satcamsim.camera.Cam_pose.lla">lla</a></code></li>
<li><code><a title="satcamsim.camera.Cam_pose.obj_to_lla" href="#satcamsim.camera.Cam_pose.obj_to_lla">obj_to_lla</a></code></li>
<li><code><a title="satcamsim.camera.Cam_pose.set_previous" href="#satcamsim.camera.Cam_pose.set_previous">set_previous</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="satcamsim.camera.Camera" href="#satcamsim.camera.Camera">Camera</a></code></h4>
<ul class="two-column">
<li><code><a title="satcamsim.camera.Camera.add_sensor" href="#satcamsim.camera.Camera.add_sensor">add_sensor</a></code></li>
<li><code><a title="satcamsim.camera.Camera.chunky_swath" href="#satcamsim.camera.Camera.chunky_swath">chunky_swath</a></code></li>
<li><code><a title="satcamsim.camera.Camera.default_swath" href="#satcamsim.camera.Camera.default_swath">default_swath</a></code></li>
<li><code><a title="satcamsim.camera.Camera.multiprocess_swath" href="#satcamsim.camera.Camera.multiprocess_swath">multiprocess_swath</a></code></li>
<li><code><a title="satcamsim.camera.Camera.multithread_swath" href="#satcamsim.camera.Camera.multithread_swath">multithread_swath</a></code></li>
<li><code><a title="satcamsim.camera.Camera.postprocess" href="#satcamsim.camera.Camera.postprocess">postprocess</a></code></li>
<li><code><a title="satcamsim.camera.Camera.set_pose" href="#satcamsim.camera.Camera.set_pose">set_pose</a></code></li>
<li><code><a title="satcamsim.camera.Camera.simulate_swath" href="#satcamsim.camera.Camera.simulate_swath">simulate_swath</a></code></li>
<li><code><a title="satcamsim.camera.Camera.take_line_img" href="#satcamsim.camera.Camera.take_line_img">take_line_img</a></code></li>
<li><code><a title="satcamsim.camera.Camera.take_swath_img_raw" href="#satcamsim.camera.Camera.take_swath_img_raw">take_swath_img_raw</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="satcamsim.camera.Interior_orientation" href="#satcamsim.camera.Interior_orientation">Interior_orientation</a></code></h4>
</li>
<li>
<h4><code><a title="satcamsim.camera.Sensor" href="#satcamsim.camera.Sensor">Sensor</a></code></h4>
<ul class="">
<li><code><a title="satcamsim.camera.Sensor.get_object_coordinates" href="#satcamsim.camera.Sensor.get_object_coordinates">get_object_coordinates</a></code></li>
<li><code><a title="satcamsim.camera.Sensor.get_px_corners" href="#satcamsim.camera.Sensor.get_px_corners">get_px_corners</a></code></li>
<li><code><a title="satcamsim.camera.Sensor.pixels_to_imgcoord" href="#satcamsim.camera.Sensor.pixels_to_imgcoord">pixels_to_imgcoord</a></code></li>
<li><code><a title="satcamsim.camera.Sensor.take_line_img" href="#satcamsim.camera.Sensor.take_line_img">take_line_img</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>